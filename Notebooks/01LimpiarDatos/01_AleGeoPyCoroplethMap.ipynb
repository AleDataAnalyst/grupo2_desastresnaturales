{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloropleth map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Crear mapa de cloropletas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar geopandas, shapely.geometry y plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "# geopy-python: librería para geocoding\n",
    "# geocoders: lo mismo que geopy\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando dataset ../../Data/02ParaLimpiar/02desastres_paralimpiar.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/02ParaLimpiar/02desastres_paralimpiar.csv', encoding='utf-8', delimiter=';', engine='python')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar carga de dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Resumen básico shape, info, head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16636, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# Resultado: 16636 filas y 20 columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16636 entries, 0 to 16635\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Dis No             16636 non-null  object \n",
      " 1   Year               16636 non-null  int64  \n",
      " 2   Seq                16636 non-null  int64  \n",
      " 3   Disaster Subgroup  16636 non-null  object \n",
      " 4   Disaster Type      16636 non-null  object \n",
      " 5   Disaster Subtype   13313 non-null  object \n",
      " 6   Country            16636 non-null  object \n",
      " 7   ISO                16636 non-null  object \n",
      " 8   Region             16636 non-null  object \n",
      " 9   Continent          16636 non-null  object \n",
      " 10  Location           14825 non-null  object \n",
      " 11  Origin             4085 non-null   object \n",
      " 12  Associated Dis     3593 non-null   object \n",
      " 13  Dis Mag Value      5064 non-null   float64\n",
      " 14  Dis Mag Scale      15416 non-null  object \n",
      " 15  Latitude           2775 non-null   object \n",
      " 16  Longitude          2775 non-null   object \n",
      " 17  Start Year         16636 non-null  int64  \n",
      " 18  Start Month        16241 non-null  float64\n",
      " 19  Start Day          13021 non-null  float64\n",
      " 20  End Year           16636 non-null  int64  \n",
      " 21  End Month          15936 non-null  float64\n",
      " 22  End Day            13105 non-null  float64\n",
      " 23  Total Deaths       11838 non-null  float64\n",
      " 24  Total Affected     12143 non-null  float64\n",
      " 25  Total Damages Adj  5366 non-null   float64\n",
      "dtypes: float64(8), int64(4), object(14)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Region</th>\n",
       "      <th>Continent</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Total Damages Adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-9002-CPV</td>\n",
       "      <td>1900</td>\n",
       "      <td>9002</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Cabo Verde</td>\n",
       "      <td>CPV</td>\n",
       "      <td>Western Africa</td>\n",
       "      <td>Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dis No  Year   Seq Disaster Subgroup Disaster Type Disaster Subtype  \\\n",
       "0  1900-9002-CPV  1900  9002    Climatological       Drought          Drought   \n",
       "\n",
       "      Country  ISO          Region Continent  ... Longitude Start Year  \\\n",
       "0  Cabo Verde  CPV  Western Africa    Africa  ...       NaN       1900   \n",
       "\n",
       "  Start Month  Start Day End Year End Month End Day  Total Deaths  \\\n",
       "0         NaN        NaN     1900       NaN     NaN       11000.0   \n",
       "\n",
       "   Total Affected  Total Damages Adj  \n",
       "0             NaN                NaN  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1        NaN\n",
       "2         14\n",
       "3        NaN\n",
       "4        NaN\n",
       "5        NaN\n",
       "6        NaN\n",
       "7        NaN\n",
       "8        NaN\n",
       "9      32.04\n",
       "10     33.05\n",
       "11    1.51 N\n",
       "12       NaN\n",
       "13       NaN\n",
       "14       NaN\n",
       "15      38.5\n",
       "16       NaN\n",
       "17       NaN\n",
       "18       NaN\n",
       "19       NaN\n",
       "20       NaN\n",
       "21     44.05\n",
       "22       NaN\n",
       "23       NaN\n",
       "24       NaN\n",
       "25       NaN\n",
       "26       NaN\n",
       "27       NaN\n",
       "28       9.8\n",
       "29        36\n",
       "30       NaN\n",
       "31       NaN\n",
       "32       NaN\n",
       "33       NaN\n",
       "34       NaN\n",
       "35       NaN\n",
       "36       NaN\n",
       "37    -3.924\n",
       "38       NaN\n",
       "39       NaN\n",
       "Name: Latitude, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Latitude'][:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2         -91\n",
       "3         NaN\n",
       "4         NaN\n",
       "5         NaN\n",
       "6         NaN\n",
       "7         NaN\n",
       "8         NaN\n",
       "9       76.16\n",
       "10       71.4\n",
       "11    78.46 W\n",
       "12        NaN\n",
       "13        NaN\n",
       "14        NaN\n",
       "15       69.9\n",
       "16        NaN\n",
       "17        NaN\n",
       "18        NaN\n",
       "19        NaN\n",
       "20        NaN\n",
       "21       6.14\n",
       "22        NaN\n",
       "23        NaN\n",
       "24        NaN\n",
       "25        NaN\n",
       "26        NaN\n",
       "27        NaN\n",
       "28        -84\n",
       "29          4\n",
       "30        NaN\n",
       "31        NaN\n",
       "32        NaN\n",
       "33        NaN\n",
       "34        NaN\n",
       "35        NaN\n",
       "36        NaN\n",
       "37     101.82\n",
       "38        NaN\n",
       "39        NaN\n",
       "Name: Longitude, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Longitude'][:40]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtros para Location y geolocalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorías geográficas\n",
    "geographical_data = df[['Location', 'ISO', 'Country', 'Region', 'Continent']]\n",
    "\n",
    "# Categorías de magnitud\n",
    "magnitude_data = df[['Dis Mag Scale', 'Dis Mag Value']]\n",
    "\n",
    "# Categorías de geolocalización\n",
    "geolocation_data = df[['Latitude', 'Longitude']]\n",
    "\n",
    "# Categorías de fecha de Earthquake\n",
    "datetime_data = df[['Start Day', 'Start Month', 'Start Year', 'End Day', 'End Month', 'End Year']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiar coordenadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para limpiar coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convertir 'Latitude' y 'Longitude' a string\n",
    "# df['Latitude'] = df['Latitude'].astype(str)\n",
    "# df['Longitude'] = df['Longitude'].astype(str)\n",
    "\n",
    "# # # Aplicar valores negativos donde Latitude y Longitude contengan S o W\n",
    "# # df.loc[df['Latitude'].str.contains('S'), 'Latitude'] *= -1\n",
    "# # df.loc[df['Longitude'].str.contains('W'), 'Longitude'] *= -1\n",
    "\n",
    "# # Limpiar las coordenadas latitude y longitude\n",
    "# # df['Latitude'] = df['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "# # df['Longitude'] = df['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "# df['Latitude'] = df['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "# df['Longitude'] = df['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# # Eliminar puntos finales\n",
    "# df['Latitude'] = df['Latitude'].str.rstrip('.')\n",
    "# df['Longitude'] = df['Longitude'].str.rstrip('.')\n",
    "\n",
    "# # Cambiar strings vacíos a NaN\n",
    "# df['Latitude'] = df['Latitude'].replace('', np.nan)\n",
    "# df['Longitude'] = df['Longitude'].replace('', np.nan)\n",
    "\n",
    "# # Convertir coordenadas válidas a float\n",
    "# df['Latitude'] = df['Latitude'].astype(float)\n",
    "# df['Longitude'] = df['Longitude'].astype(float)\n",
    "\n",
    "# # Identificar valores anómalos a partir de los grados\n",
    "# anomalous_lat = df['Latitude'].abs() > 90\n",
    "# anomalous_lon = df['Longitude'].abs() > 180\n",
    "\n",
    "# # Configurar valores anómalos a NaN\n",
    "# df.loc[anomalous_lat, 'Latitude'] = np.nan\n",
    "# df.loc[anomalous_lon, 'Longitude'] = np.nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lirería re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\d\n",
    "\n",
    "Para los patrones de Unicode (str):\n",
    "Coincide con cualquier dígito decimal de Unicode (es decir, cualquier carácter de la categoría de caracteres de Unicode [Nd]). Esto incluye a [0-9], y también muchos otros caracteres de dígitos. Si se usa el indicador ASCII, sólo coincide con [0-9]."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re.sub(pattern, repl, string, count=0, flags=0)¶\n",
    "Retorna la cadena obtenida reemplazando las ocurrencias no superpuestas del pattern («patrón») en la string («cadena») por el reemplazo de repl. Si el patrón no se encuentra, se retorna string sin cambios. repl puede ser una cadena o una función; si es una cadena, cualquier barra inversa escapada en ella es procesada. Es decir, \\n se convierte en un carácter de una sola línea nueva, \\r se convierte en un retorno de carro, y así sucesivamente. Los escapes desconocidos de las letras ASCII se reservan para un uso futuro y se tratan como errores. Otros escapes desconocidos como \\& no se utilizan. Las referencias inversas, como \\6, se reemplazan por la subcadena que corresponde al grupo 6 del patrón. Por ejemplo:\n",
    "\n",
    ">>>\n",
    "re.sub(r'def\\s+([a-zA-Z_][a-zA-Z_0-9]*)\\s*\\(\\s*\\):',\n",
    "       r'static PyObject*\\npy_\\1(void)\\n{',\n",
    "       'def myfunc():')\n",
    "'static PyObject*\\npy_myfunc(void)\\n{'\n",
    "Si repl es una función, se llama para cada ocurrencia no superpuesta de pattern. La función toma un solo argumento objeto match, y retorna la cadena de sustitución. Por ejemplo:\n",
    "\n",
    ">>>\n",
    "def dashrepl(matchobj):\n",
    "    if matchobj.group(0) == '-': return ' '\n",
    "    else: return '-'\n",
    "re.sub('-{1,2}', dashrepl, 'pro----gram-files')\n",
    "'pro--gram files'\n",
    "re.sub(r'\\sAND\\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE)\n",
    "'Baked Beans & Spam'\n",
    "El patrón puede ser una cadena o un objeto patrón.\n",
    "\n",
    "El argumento opcional count («recuento») es el número máximo de ocurrencias de patrones a ser reemplazados; count debe ser un número entero no negativo. Si se omite o es cero, todas las ocurrencias serán reemplazadas. Las coincidencias vacías del patrón se reemplazan sólo cuando no están adyacentes a una coincidencia vacía anterior, así que sub('x*', '-', 'abxd') retorna '-a-b--d-'.\n",
    "\n",
    "En los argumentos repl de tipo cadena, además de los escapes de caracteres y las referencias inversas descritas anteriormente, \\g<name> usará la subcadena coincidente con el grupo llamado name, como se define en la sintaxis (?P<name>...). \\g<number> utiliza el número de grupo correspondiente; \\g<2> es por lo tanto equivalente a \\2, pero no es ambiguo en un reemplazo como sucede con \\g<2>0. \\20 se interpretaría como una referencia al grupo 20, no como una referencia al grupo 2 seguido del carácter literal '0'. La referencia inversa \\g<0> sustituye en toda la subcadena coincidente con la RE.\n",
    "\n",
    "Distinto en la versión 3.1: Se añadió el argumento de los indicadores opcionales.\n",
    "\n",
    "Distinto en la versión 3.5: Los grupos no coincidentes son reemplazados por una cadena vacía.\n",
    "\n",
    "Distinto en la versión 3.6: Los escapes desconocidos en el pattern que consisten en '\\' y una letra ASCII ahora son errores.\n",
    "\n",
    "Distinto en la versión 3.7: Los escapes desconocidos en repl que consisten en '\\' y una letra ASCII ahora son errores.\n",
    "\n",
    "Distinto en la versión 3.7: Las coincidencias vacías para el patrón se reemplazan cuando están adyacentes a una coincidencia anterior no vacía.\n",
    "\n",
    "Obsoleto desde la versión 3.11: Group id containing anything except ASCII digits. Group name containing characters outside the ASCII range (b'\\x00'-b'\\x7f') in bytes replacement strings.\n",
    "\n",
    "re.subn(pattern, repl, string, count=0, flags=0)\n",
    "Realiza la misma operación que sub(), pero retorna una tupla (new_string, number_of_subs_made).\n",
    "\n",
    "Distinto en la versión 3.1: Se añadió el argumento de los indicadores opcionales.\n",
    "\n",
    "Distinto en la versión 3.5: Los grupos no coincidentes son reemplazados por una cadena vacía.\n",
    "\n",
    "re.escape(pattern)\n",
    "Caracteres de escape especiales en pattern (» patrón»). Esto es útil si quieres hacer coincidir una cadena literal arbitraria que puede tener metacaracteres de expresión regular en ella. Por ejemplo:\n",
    "\n",
    ">>>\n",
    "print(re.escape('https://www.python.org'))\n",
    "https://www\\.python\\.org\n",
    "\n",
    "legal_chars = string.ascii_lowercase + string.digits + \"!#$%&'*+-.^_`|~:\"\n",
    "print('[%s]+' % re.escape(legal_chars))\n",
    "[abcdefghijklmnopqrstuvwxyz0123456789!\\#\\$%\\&'\\*\\+\\-\\.\\^_`\\|\\~:]+\n",
    "\n",
    "operators = ['+', '-', '*', '/', '**']\n",
    "print('|'.join(map(re.escape, sorted(operators, reverse=True))))\n",
    "/|\\-|\\+|\\*\\*|\\*\n",
    "Esta función no debe usarse para la cadena de reemplazo en sub() y subn(), sólo deben escaparse las barras inversas. Por ejemplo:\n",
    "\n",
    ">>>\n",
    "digits_re = r'\\d+'\n",
    "sample = '/usr/sbin/sendmail - 0 errors, 12 warnings'\n",
    "print(re.sub(digits_re, digits_re.replace('\\\\', r'\\\\'), sample))\n",
    "/usr/sbin/sendmail - \\d+ errors, \\d+ warnings\n",
    "Distinto en la versión 3.3: El carácter de '_' ya no se escapa.\n",
    "\n",
    "Distinto en la versión 3.7: Sólo se escapan los caracteres que pueden tener un significado especial en una expresión regular. Como resultado, '!', '\"', '%', \"'\", ',', '/', ':', ';', '<', '=', '>', '@' y \"`\" ya no se escapan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        nan\n",
      "1        nan\n",
      "2         14\n",
      "3        nan\n",
      "4        nan\n",
      "5        nan\n",
      "6        nan\n",
      "7        nan\n",
      "8        nan\n",
      "9      32.04\n",
      "10     33.05\n",
      "11    1.51 N\n",
      "12       nan\n",
      "13       nan\n",
      "14       nan\n",
      "15      38.5\n",
      "16       nan\n",
      "17       nan\n",
      "18       nan\n",
      "19       nan\n",
      "20       nan\n",
      "21     44.05\n",
      "22       nan\n",
      "23       nan\n",
      "24       nan\n",
      "25       nan\n",
      "26       nan\n",
      "27       nan\n",
      "28       9.8\n",
      "29        36\n",
      "30       nan\n",
      "31       nan\n",
      "32       nan\n",
      "33       nan\n",
      "34       nan\n",
      "35       nan\n",
      "36       nan\n",
      "37    -3.924\n",
      "38       nan\n",
      "39       nan\n",
      "Name: Latitude, dtype: object\n",
      "0         nan\n",
      "1         nan\n",
      "2         -91\n",
      "3         nan\n",
      "4         nan\n",
      "5         nan\n",
      "6         nan\n",
      "7         nan\n",
      "8         nan\n",
      "9       76.16\n",
      "10       71.4\n",
      "11    78.46 W\n",
      "12        nan\n",
      "13        nan\n",
      "14        nan\n",
      "15       69.9\n",
      "16        nan\n",
      "17        nan\n",
      "18        nan\n",
      "19        nan\n",
      "20        nan\n",
      "21       6.14\n",
      "22        nan\n",
      "23        nan\n",
      "24        nan\n",
      "25        nan\n",
      "26        nan\n",
      "27        nan\n",
      "28        -84\n",
      "29          4\n",
      "30        nan\n",
      "31        nan\n",
      "32        nan\n",
      "33        nan\n",
      "34        nan\n",
      "35        nan\n",
      "36        nan\n",
      "37     101.82\n",
      "38        nan\n",
      "39        nan\n",
      "Name: Longitude, dtype: object\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39m40\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[39m# Aplicar valores negativos donde Latitude y Longitude contengan S o W\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# df.loc[df['Latitude'].str.contains('S'), 'Latitude'] *= -1\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# df.loc[df['Longitude'].str.contains('W'), 'Longitude'] *= -1\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m# df['Latitude'] = df['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# df['Longitude'] = df['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mLatitude\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: re\u001b[39m.\u001b[39;49msub(\u001b[39m'\u001b[39;49m\u001b[39m[^\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39md.--]\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, x\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39;49m]) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(x, \u001b[39mstr\u001b[39;49m) \u001b[39melse\u001b[39;49;00m x)\n\u001b[0;32m     17\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md.--]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, x\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m x)\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39m40\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39m40\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[39m# Aplicar valores negativos donde Latitude y Longitude contengan S o W\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# df.loc[df['Latitude'].str.contains('S'), 'Latitude'] *= -1\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# df.loc[df['Longitude'].str.contains('W'), 'Longitude'] *= -1\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m# df['Latitude'] = df['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# df['Longitude'] = df['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md.--]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, x\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m x)\n\u001b[0;32m     17\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md.--]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, x\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m x)\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39m40\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "# Convertir 'Latitude' y 'Longitude' a string\n",
    "df['Latitude'] = df['Latitude'].astype(str)\n",
    "df['Longitude'] = df['Longitude'].astype(str)\n",
    "print(df['Latitude'][:40])\n",
    "print(df['Longitude'][:40])\n",
    "\n",
    "# Aplicar valores negativos donde Latitude y Longitude contengan S o W\n",
    "# df.loc[df['Latitude'].str.contains('S'), 'Latitude'] *= -1\n",
    "# df.loc[df['Longitude'].str.contains('W'), 'Longitude'] *= -1\n",
    "# print(df['Latitude'][:40])\n",
    "# print(df['Longitude'][:40])\n",
    "\n",
    "# Limpiar las coordenadas latitude y longitude\n",
    "# df['Latitude'] = df['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "# df['Longitude'] = df['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "df['Latitude'] = df['Latitude'].apply(lambda x: re.sub('[^\\d.--]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "df['Longitude'] = df['Longitude'].apply(lambda x: re.sub('[^\\d.--]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "print(df['Latitude'][:40])\n",
    "print(df['Longitude'][:40])\n",
    "\n",
    "# Eliminar puntos finales\n",
    "df['Latitude'] = df['Latitude'].str.rstrip('.')\n",
    "df['Longitude'] = df['Longitude'].str.rstrip('.')\n",
    "print(df['Latitude'][:40])\n",
    "print(df['Longitude'][:40])\n",
    "\n",
    "# Cambiar strings vacíos a NaN\n",
    "df['Latitude'] = df['Latitude'].replace('', np.nan)\n",
    "df['Longitude'] = df['Longitude'].replace('', np.nan)\n",
    "print(df['Latitude'][:40])\n",
    "print(df['Longitude'][:40])\n",
    "\n",
    "# Convertir coordenadas válidas a float\n",
    "df['Latitude'] = df['Latitude'].astype(float)\n",
    "df['Longitude'] = df['Longitude'].astype(float)\n",
    "print(df['Latitude'][:40])\n",
    "print(df['Longitude'][:40])\n",
    "\n",
    "# Identificar valores anómalos a partir de los grados\n",
    "anomalous_lat = df['Latitude'].abs() > 90\n",
    "anomalous_lon = df['Longitude'].abs() > 180\n",
    "print(df['Latitude'][:40])\n",
    "print(df['Longitude'][:40])\n",
    "\n",
    "# Configurar valores anómalos a NaN\n",
    "df.loc[anomalous_lat, 'Latitude'] = np.nan\n",
    "df.loc[anomalous_lon, 'Longitude'] = np.nan\n",
    "print(df['Latitude'][:40])\n",
    "print(df['Longitude'][:40])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función re.sub() se usa para eliminar caracteres que no son dígitos de las coordenadas.\n",
    "'[^\\d.-]' es un patrón de expresión regular que coincide con cualquier carácter que no sea un dígito, un punto (punto decimal) o un guión (signo negativo).\n",
    "x.split('.', 1)[0] divide la cadena en la primera aparición del punto decimal y conserva solo la parte anterior. Esto garantiza que solo se conserve la parte válida del valor de la coordenada.\n",
    "La función str.rstrip('.') se utiliza para eliminar los puntos finales de las coordenadas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación del fragmento de código para identificar valores anómalos de latitud y longitud en el DataFrame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### anomalous_lat = df['Latitud'].abs() > 90:\n",
    "\n",
    "* df['Latitude'].abs() devuelve los valores absolutos de la columna 'Latitude'.\n",
    "* > 90 comprueba si los valores de latitud absoluta son superiores a 90.\n",
    "Esta expresión crea una serie booleana (anomalous_lat) donde True indica que la latitud es anómala (fuera del rango válido de -90 a 90 grados).\n",
    "\n",
    "#### anomalous_lon = df['Longitud'].abs() > 180:\n",
    "\n",
    "df['Longitud'].abs() devuelve los valores absolutos de la columna 'Longitud'.\n",
    "> 180 comprueba si los valores de longitud absoluta son superiores a 180.\n",
    "Esta expresión crea una serie booleana (anomalous_lon) donde True indica que la longitud es anómala (fuera del rango válido de -180 a 180 grados).\n",
    "Las series booleanas anómalas_lat y anómalas_lon resultantes tendrán valores verdaderos para las filas donde los valores de latitud o longitud están fuera del rango válido, y falsos para las filas con coordenadas válidas.\n",
    "\n",
    "Se pueden usar estas series booleanas para filtrar o manejar las filas con coordenadas anómalas en su marco de datos. Por ejemplo, se pueden eliminar las filas con coordenadas anómalas utilizando el siguiente código:\n",
    "\n",
    "df_cleaned_coords = df[~(anomalous_lat | anomalous_lon)]\n",
    "\n",
    "El operador ~ niega la serie booleana, por lo que ~(anomalous_lat | anomalou_lon) selecciona filas donde ni la latitud ni la longitud son anómalas. El DataFrame resultante, df_cleaned_coords, contendrá solo las filas con coordenadas válidas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de verificación de limpieza de coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Latitude'])\n",
    "print(df['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Latitude'].unique())\n",
    "print(df['Longitude'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinar filas específicas para verificar si el proceso de limpieza ha manejado los valores anómalos correctamente.\n",
    "print(df.loc[68, 'Latitude'])\n",
    "print(df.loc[68, 'Longitude'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Longitude', 'Latitude']].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaciones para comprobar coordenadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot para identificar outliers de Latitude y Longitude"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../Documentacion/CoordenadasLatitudesLongitudes.webp\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df['Longitude'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayor concentración de desastres naturales a partir de Longitude se ubica entre los 10º y 100º, afectando a países de África y Eurasia.\n",
    "Los outliers para Longitude se concentran entre los -125º y los -180º, es decir, Pacífico Occidental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df['Latitude'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coropleth map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un GeoDataFrame a partir del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['Longitude'], df['Latitude']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(df['Longitude'], df['Latitude'])]\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('coordenadas.geojson', driver='GeoJSON')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar el geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('coordenadas.geojson')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapa de coropletas para Magnitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar 'Disaster Mag Scale' and 'Disaster Mag Value' en una columna compuesta\n",
    "df['Magnitude'] = df['Dis Mag Scale'] + ' ' + df['Dis Mag Value'].astype(str)\n",
    "\n",
    "# Crear GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(df['Longitude'], df['Latitude'])]\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# Crear el choropleth usando la columna compuesta 'Magnitude'\n",
    "fig = make_subplots(specs=[[{\"type\": \"choropleth\"}]])\n",
    "fig.add_trace(\n",
    "    go.Choroplethmapbox(\n",
    "        geojson=gdf.geometry.__geo_interface__,\n",
    "        locations=gdf.index,\n",
    "        z=gdf['Magnitude'],\n",
    "        colorscale='Viridis',\n",
    "        marker_opacity=0.7,\n",
    "        marker_line_width=0,\n",
    "        featureidkey='properties.index',  # Especificar la característica id key\n",
    "        colorbar=dict(title='Magnitude')  # Especificar el título de colorbar\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    mapbox_zoom=2,\n",
    "    mapbox_center={\"lat\": 0, \"lon\": 0}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da error de traceback call y tarda demasiado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapa de coropletas para Disaster Subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(df['Longitude'], df['Latitude'])]\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# Crear el choropleth usando la columna compuesta 'Magnitude'\n",
    "fig = make_subplots(specs=[[{\"type\": \"choropleth\"}]])\n",
    "fig.add_trace(\n",
    "    go.Choroplethmapbox(\n",
    "        geojson=gdf.geometry.__geo_interface__,\n",
    "        locations=gdf.index,\n",
    "        z=gdf['Disaster Subtype'],\n",
    "        colorscale='Viridis',\n",
    "        # marker_opacity=0.7,\n",
    "        # marker_line_width=0,\n",
    "        featureidkey='properties.index',  # Especificar la característica id key\n",
    "        colorbar=dict(title='Magnitude')  # Especificar el título de colorbar\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    mapbox_zoom=2,\n",
    "    mapbox_center={\"lat\": 0, \"lon\": 0}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.choropleth(df, locations='iso', color='Magnitude', hover_name='Country')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
