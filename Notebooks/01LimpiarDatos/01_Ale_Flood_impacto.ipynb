{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impacto humano de Inundaciones (Flood)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import re\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar base de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02desastres_paralimpiar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Region</th>\n",
       "      <th>Continent</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Total Damages Adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-9002-CPV</td>\n",
       "      <td>1900</td>\n",
       "      <td>9002</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Cabo Verde</td>\n",
       "      <td>CPV</td>\n",
       "      <td>Western Africa</td>\n",
       "      <td>Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900-9001-IND</td>\n",
       "      <td>1900</td>\n",
       "      <td>9001</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1902-0012-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>12</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>GTM</td>\n",
       "      <td>Central America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>-91</td>\n",
       "      <td>1902</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1902</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>843726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1902-0003-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>3</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>GTM</td>\n",
       "      <td>Central America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1902</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1902</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902-0010-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>10</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>GTM</td>\n",
       "      <td>Central America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1902</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1902</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1903-0006-CAN</td>\n",
       "      <td>1903</td>\n",
       "      <td>6</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Mass movement (dry)</td>\n",
       "      <td>Rockfall</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1903</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1903</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1903-0012-COM</td>\n",
       "      <td>1903</td>\n",
       "      <td>12</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>Comoros (the)</td>\n",
       "      <td>COM</td>\n",
       "      <td>Eastern Africa</td>\n",
       "      <td>Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904-0003-BGD</td>\n",
       "      <td>1904</td>\n",
       "      <td>3</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BGD</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1904</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1904</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1905-0005-CAN</td>\n",
       "      <td>1905</td>\n",
       "      <td>5</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Mass movement (dry)</td>\n",
       "      <td>Rockfall</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1905</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1905</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1905-0003-IND</td>\n",
       "      <td>1905</td>\n",
       "      <td>3</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>76.16</td>\n",
       "      <td>1905</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1905</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>812477.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dis No  Year   Seq Disaster Subgroup        Disaster Type  \\\n",
       "0  1900-9002-CPV  1900  9002    Climatological              Drought   \n",
       "1  1900-9001-IND  1900  9001    Climatological              Drought   \n",
       "2  1902-0012-GTM  1902    12       Geophysical           Earthquake   \n",
       "3  1902-0003-GTM  1902     3       Geophysical    Volcanic activity   \n",
       "4  1902-0010-GTM  1902    10       Geophysical    Volcanic activity   \n",
       "5  1903-0006-CAN  1903     6       Geophysical  Mass movement (dry)   \n",
       "6  1903-0012-COM  1903    12       Geophysical    Volcanic activity   \n",
       "7  1904-0003-BGD  1904     3    Meteorological                Storm   \n",
       "8  1905-0005-CAN  1905     5       Geophysical  Mass movement (dry)   \n",
       "9  1905-0003-IND  1905     3       Geophysical           Earthquake   \n",
       "\n",
       "   Disaster Subtype        Country  ISO            Region Continent  ...  \\\n",
       "0           Drought     Cabo Verde  CPV    Western Africa    Africa  ...   \n",
       "1           Drought          India  IND     Southern Asia      Asia  ...   \n",
       "2   Ground movement      Guatemala  GTM   Central America  Americas  ...   \n",
       "3          Ash fall      Guatemala  GTM   Central America  Americas  ...   \n",
       "4          Ash fall      Guatemala  GTM   Central America  Americas  ...   \n",
       "5          Rockfall         Canada  CAN  Northern America  Americas  ...   \n",
       "6          Ash fall  Comoros (the)  COM    Eastern Africa    Africa  ...   \n",
       "7  Tropical cyclone     Bangladesh  BGD     Southern Asia      Asia  ...   \n",
       "8          Rockfall         Canada  CAN  Northern America  Americas  ...   \n",
       "9   Ground movement          India  IND     Southern Asia      Asia  ...   \n",
       "\n",
       "  Longitude Start Year Start Month  Start Day End Year End Month End Day  \\\n",
       "0       NaN       1900         NaN        NaN     1900       NaN     NaN   \n",
       "1       NaN       1900         NaN        NaN     1900       NaN     NaN   \n",
       "2       -91       1902         4.0       18.0     1902       4.0    18.0   \n",
       "3       NaN       1902         4.0        8.0     1902       4.0     8.0   \n",
       "4       NaN       1902        10.0       24.0     1902      10.0    24.0   \n",
       "5       NaN       1903         4.0       29.0     1903       4.0    29.0   \n",
       "6       NaN       1903         NaN        NaN     1903       NaN     NaN   \n",
       "7       NaN       1904        11.0        NaN     1904      11.0     NaN   \n",
       "8       NaN       1905         8.0       13.0     1905       8.0    13.0   \n",
       "9     76.16       1905         4.0        4.0     1905       4.0     4.0   \n",
       "\n",
       "   Total Deaths  Total Affected  Total Damages Adj  \n",
       "0       11000.0             NaN                NaN  \n",
       "1     1250000.0             NaN                NaN  \n",
       "2        2000.0             NaN           843726.0  \n",
       "3        1000.0             NaN                NaN  \n",
       "4        6000.0             NaN                NaN  \n",
       "5          76.0            23.0                NaN  \n",
       "6          17.0             NaN                NaN  \n",
       "7           NaN             NaN                NaN  \n",
       "8          18.0            18.0                NaN  \n",
       "9       20000.0             NaN           812477.0  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../Data/02ParaLimpiar/02desastres_paralimpiar.csv', delimiter=';', encoding='utf-8')\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Inicial Básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16636, 26)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16636 entries, 0 to 16635\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Dis No             16636 non-null  object \n",
      " 1   Year               16636 non-null  int64  \n",
      " 2   Seq                16636 non-null  int64  \n",
      " 3   Disaster Subgroup  16636 non-null  object \n",
      " 4   Disaster Type      16636 non-null  object \n",
      " 5   Disaster Subtype   13313 non-null  object \n",
      " 6   Country            16636 non-null  object \n",
      " 7   ISO                16636 non-null  object \n",
      " 8   Region             16636 non-null  object \n",
      " 9   Continent          16636 non-null  object \n",
      " 10  Location           14825 non-null  object \n",
      " 11  Origin             4085 non-null   object \n",
      " 12  Associated Dis     3593 non-null   object \n",
      " 13  Dis Mag Value      5064 non-null   float64\n",
      " 14  Dis Mag Scale      15416 non-null  object \n",
      " 15  Latitude           2775 non-null   object \n",
      " 16  Longitude          2775 non-null   object \n",
      " 17  Start Year         16636 non-null  int64  \n",
      " 18  Start Month        16241 non-null  float64\n",
      " 19  Start Day          13021 non-null  float64\n",
      " 20  End Year           16636 non-null  int64  \n",
      " 21  End Month          15936 non-null  float64\n",
      " 22  End Day            13105 non-null  float64\n",
      " 23  Total Deaths       11838 non-null  float64\n",
      " 24  Total Affected     12143 non-null  float64\n",
      " 25  Total Damages Adj  5366 non-null   float64\n",
      "dtypes: float64(8), int64(4), object(14)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro Disaster Type == Flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = df['Disaster Type'] == 'Flood'\n",
    "df_flood = df[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Region</th>\n",
       "      <th>Continent</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Total Damages Adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1906-0023-BEL</td>\n",
       "      <td>1906</td>\n",
       "      <td>23</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>BEL</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Europe</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1906</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1906</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1906-0024-BEL</td>\n",
       "      <td>1906</td>\n",
       "      <td>24</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>BEL</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Europe</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1906</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1906</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dis No  Year  Seq Disaster Subgroup Disaster Type Disaster Subtype  \\\n",
       "12  1906-0023-BEL  1906   23      Hydrological         Flood              NaN   \n",
       "13  1906-0024-BEL  1906   24      Hydrological         Flood              NaN   \n",
       "\n",
       "    Country  ISO          Region Continent  ... Longitude Start Year  \\\n",
       "12  Belgium  BEL  Western Europe    Europe  ...       NaN       1906   \n",
       "13  Belgium  BEL  Western Europe    Europe  ...       NaN       1906   \n",
       "\n",
       "   Start Month  Start Day End Year End Month End Day  Total Deaths  \\\n",
       "12         5.0       14.0     1906       5.0    14.0           6.0   \n",
       "13         4.0        NaN     1906       4.0     NaN           NaN   \n",
       "\n",
       "    Total Affected  Total Damages Adj  \n",
       "12             NaN                NaN  \n",
       "13             NaN                NaN  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flood.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5808, 26)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flood['Disaster Type'].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de coordenadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para limpiar coordenadas filtrado para df_flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores anómalos de Latitude: [357.0, 411.44, 564.78, -865.05, 270.63, 350.75, 388.5, 151.82, 940.04, 193.8, -295.02, -405.21, 125.95, 289.08, 213.52, 334.55, 420.68, 194.43, 301.14, 342.7, 370.53, -104.9, 465.99, -528.26, 398.68, 191.36, 236.39, -189.54, 282.42, 227.7, 369.29, -344.81, 445.99, 304.56, 359.16, 258.63, 229.04, 491.36, 532.73, 146.06, -617.95, 448.01, -133.89, 439.96, 431.6, 165.92, 822.39, -140.1, 205.95, 240.59, -183.1, 246.17, 163.19, 396.15, 166.08, 759.78, 420.41, 183.12, -248.01, -202.3, -156.18, 358.44, 150.1, 271.82, 287.4, -158.38, -203.46, 98.8, 500.04, 443.29, 136.88, 216.96, 439.96, 303.63, 289.64, 139.19, 382.14, 388.28, 375.6, -164.64, -414.04, 271.89, -383.65, 440.62, 359.05, 250.0, 233.83, 303.4, 233.58, 368.56, 382.08, 402.89, -881.66, -223.62, 270.33, 101.74, 420.68, -315.73, -255.69, 570.69, 365.24, 364.94, -121.14, -351.09, 282.3, -115.04, -697.8, -441.03, 282.3, 278.09, 374.59, 394.74, 738.0, 414.57, 666.58, 730.95, 271.5, 325.83, 366.41, 484.05, -252.2, 440.62, 196.56, 417.58, 335.13, 331.77, 262.07, 278.09, 378.14, 380.63, -655.87, 282.3, 278.09, 365.24, 107.12, 218.73, 269.2, 268.95, 336.3, 194.81, 148.42, -398.65, 365.24, 364.94, 350.13, 343.43, 155.51, 468.15, -215.15, 440.62, 402.89, 719.3, -269.9, 208.14, -431.42, 341.94, -506.02, -326.33]\n",
      "Valores anómalos de Longitude: [993.5, -921.21, 959.71, 655.01, 655.05, -745.11, 825.86, 204.53, 253.89, -924.61, -729.88, -716.74, 703.68, 711.26, 847.31, 847.31, 860.66, 781.54, 544.48, 477.04, -924.61, -858.78, 996.7, 860.66, 847.31, 860.66, 703.68, 703.68, 711.26, 253.89, 267.05]\n"
     ]
    }
   ],
   "source": [
    "# Convertir 'Latitude' y 'Longitude' a string\n",
    "df['Latitude'] = df['Latitude'].astype(str)\n",
    "df['Longitude'] = df['Longitude'].astype(str)\n",
    "\n",
    "# Limpiar las coordenadas de latitud y longitud\n",
    "df['Latitude'] = df['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
    "df['Longitude'] = df['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
    "\n",
    "# Quitar puntos finales\n",
    "df['Latitude'] = df['Latitude'].str.rstrip('.')\n",
    "df['Longitude'] = df['Longitude'].str.rstrip('.')\n",
    "\n",
    "# Añadir valores anómalos de latitud y longitud a listas\n",
    "anomalous_lat = []\n",
    "anomalous_lon = []\n",
    "\n",
    "def convert_coordinates(x, convert_nan=True):\n",
    "    if not x:\n",
    "        return np.nan\n",
    "\n",
    "    # Remover caracteres 'N' y 'E'\n",
    "    x = x.replace(' N', '').replace(' E', '')\n",
    "    \n",
    "    # Remover puntos extras en decimales\n",
    "    x = re.sub('^(\\d+\\.\\d{2})\\..*', r'\\1', x)\n",
    "\n",
    "    # Conversión a negativo para S y W\n",
    "    try:\n",
    "        value = float(x)\n",
    "        if x[-1] == 'S' or x[-1] == 'W':\n",
    "            return -value\n",
    "        else:\n",
    "            return value\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# Convertir a float\n",
    "df['Latitude'] = df['Latitude'].apply(convert_coordinates)\n",
    "df['Longitude'] = df['Longitude'].apply(convert_coordinates)\n",
    "\n",
    "# Redondear decimales\n",
    "df['Latitude'] = df['Latitude'].round(2)\n",
    "df['Longitude'] = df['Longitude'].round(2)\n",
    "\n",
    "# Identificación de valores anómalos fuera de rango de grados de sistema de coordenadas\n",
    "for index, row in df.iterrows():\n",
    "    latitude = row['Latitude']\n",
    "    longitude = row['Longitude']\n",
    "\n",
    "    if latitude < -90 or latitude > 90:\n",
    "        anomalous_lat.append(latitude)\n",
    "\n",
    "    if longitude < -180 or longitude > 180:\n",
    "        anomalous_lon.append(longitude)\n",
    "\n",
    "print(\"Valores anómalos de Latitude:\", anomalous_lat)\n",
    "print(\"Valores anómalos de Longitude:\", anomalous_lon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convertir 'Latitude' y 'Longitude' a string\n",
    "# df['Latitude'] = df['Latitude'].astype(str)\n",
    "# df['Longitude'] = df['Longitude'].astype(str)\n",
    "\n",
    "# # Limpiar las coordinadas de latitude y longitude\n",
    "# df['Latitude'] = df['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
    "# df['Longitude'] = df['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
    "\n",
    "# # Quitar puntos finales\n",
    "# df['Latitude'] = df['Latitude'].str.rstrip('.')\n",
    "# df['Longitude'] = df['Longitude'].str.rstrip('.')\n",
    "\n",
    "# # # Reemplazar Norte y Este con valores positivos, Sur y Oeste con negativos\n",
    "# # df['Latitude'] = df['Latitude'].apply(lambda x: float(x) if x and x[-1] != 'S' else -float(x[:-1]) if x else np.nan)\n",
    "# # df['Longitude'] = df['Longitude'].apply(lambda x: float(x) if x and x[-1] != 'W' else -float(x[:-1]) if x else np.nan)\n",
    "\n",
    "# # Función para convertir latitude y longitude\n",
    "# def convert_coordinates(x):\n",
    "#     if not x:\n",
    "#         return np.nan\n",
    "    \n",
    "#     # Remover los caracteres 'N' y 'E'\n",
    "#     x = x.replace(' N', '').replace(' E', '')\n",
    "    \n",
    "#     # Remover puntos extras en decimales\n",
    "#     x = re.sub('(?<=\\d)\\.(?=.*\\.)', '', x) # Este revisa antes del primer punto\n",
    "#     # x = re.sub('\\.(?=.*\\.)', '', x)\n",
    "    \n",
    "#     try:\n",
    "#         value = float(x)\n",
    "#         if x[-1] == 'S' or x[-1] == 'W':\n",
    "#             return -value\n",
    "#         else:\n",
    "#             return value\n",
    "#     except ValueError:\n",
    "#         return np.nan\n",
    "\n",
    "# # Convertir Latitude y Longitude a coordenadas\n",
    "# df['Latitude'] = df['Latitude'].apply(convert_coordinates)\n",
    "# df['Longitude'] = df['Longitude'].apply(convert_coordinates)\n",
    "\n",
    "# # Redondear decimales a 2 dígitos\n",
    "# df['Latitude'] = df['Latitude'].round(2)\n",
    "# df['Longitude'] = df['Longitude'].round(2)\n",
    "\n",
    "# # Identificar valores anómalos a partir de los grados,\n",
    "# # que no representen coordenadas: los que no estén dentro de 90 y -90 ni 180 y -180\n",
    "# anomalous_lat = ~df['Latitude'].between(-90, 90)\n",
    "# anomalous_lon = ~df['Longitude'].between(-180, 180)\n",
    "\n",
    "# # Configurar valores anómalos a NaN\n",
    "# # df.loc[anomalous_lat, 'Latitude'] = np.nan\n",
    "# # df.loc[anomalous_lon, 'Longitude'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crear listas vacías para almacenar valores anómalos de latitude y longitude\n",
    "# anomalous_lat = []\n",
    "# anomalous_lon = []\n",
    "\n",
    "# # Iterar sobre las filas e identificar valores anómalos\n",
    "# for index, row in df_flood.iterrows():\n",
    "#     latitude = row['Latitude']\n",
    "#     longitude = row['Longitude']\n",
    "    \n",
    "#     # Revisar si latitude y longitude son números válidos\n",
    "#     if pd.notnull(latitude) and pd.notnull(longitude):\n",
    "#         # Convertir latitude y longitude a tipo numérico si hay strings\n",
    "#         if isinstance(latitude, str):\n",
    "#             latitude = pd.to_numeric(latitude, errors='coerce')\n",
    "#         if isinstance(longitude, str):\n",
    "#             longitude = pd.to_numeric(longitude, errors='coerce')\n",
    "        \n",
    "#         # Revisar si latitude está fuera de rango (-90 to 90)\n",
    "#         if latitude < -90 or latitude > 90:\n",
    "#             anomalous_lat.append(latitude)\n",
    "        \n",
    "#         # Revisar si longitude está fuera de rango (-180 a 180)\n",
    "#         if longitude < -180 or longitude > 180:\n",
    "#             anomalous_lon.append(longitude)\n",
    "\n",
    "# # Mostrar valores anómalos de latitude y longitude\n",
    "# print(\"Valores Anómalos de Latitude:\", anomalous_lat)\n",
    "# print(\"Valores Anómalos de Longitude:\", anomalous_lon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convertir 'Latitude' y 'Longitude' a string\n",
    "# df['Latitude'] = df['Latitude'].astype(str)\n",
    "# df['Longitude'] = df['Longitude'].astype(str)\n",
    "\n",
    "# # Limpiar las coordenadas latitude y longitude\n",
    "# df['Latitude'] = df['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "# df['Longitude'] = df['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "\n",
    "# # Eliminar puntos finales\n",
    "# df['Latitude'] = df['Latitude'].str.rstrip('.')\n",
    "# df['Longitude'] = df['Longitude'].str.rstrip('.')\n",
    "\n",
    "# # Cambiar strings vacíos a NaN\n",
    "# df['Latitude'] = df['Latitude'].replace('', np.nan)\n",
    "# df['Longitude'] = df['Longitude'].replace('', np.nan)\n",
    "\n",
    "# # Convertir coordenadas válidas a float\n",
    "# df['Latitude'] = df['Latitude'].astype(float)\n",
    "# df['Longitude'] = df['Longitude'].astype(float)\n",
    "\n",
    "# # Identificar valores anómalos a partir de los grados\n",
    "# anomalous_lat = df['Latitude'].abs() > 90\n",
    "# anomalous_lon = df['Longitude'].abs() > 180\n",
    "\n",
    "# # Configurar valores anómalos a NaN\n",
    "# df.loc[anomalous_lat, 'Latitude'] = np.nan\n",
    "# df.loc[anomalous_lon, 'Longitude'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flood = df[(df['Disaster Subtype'] == 'Flood') & (df['Total Deaths'].notna())]\n",
    "\n",
    "# # Limpiar coordenadas latitude y longitude para df_flood\n",
    "# df_flood['Latitude'] = df_flood['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "# df_flood['Longitude'] = df_flood['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "\n",
    "# # Borrar puntos finales\n",
    "# df_flood['Latitude'] = df_flood['Latitude'].str.rstrip('.')\n",
    "# df_flood['Longitude'] = df_flood['Longitude'].str.rstrip('.')\n",
    "\n",
    "# # Cambiar strings vacíos a NaN\n",
    "# df_flood['Latitude'] = df_flood['Latitude'].replace('', np.nan)\n",
    "# df_flood['Longitude'] = df_flood['Longitude'].replace('', np.nan)\n",
    "\n",
    "# # Convertir coordenadas válidas a float\n",
    "# df_flood['Latitude'] = df_flood['Latitude'].astype(float)\n",
    "# df_flood['Longitude'] = df_flood['Longitude'].astype(float)\n",
    "\n",
    "# # Remover filas con coordenadas NaN\n",
    "# df_flood = df_flood.dropna(subset=['Latitude', 'Longitude'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filtrar el df_flood DataFrame para Disaster Subtype 'Flood' con non-null values en columnas específicas\n",
    "# df_flood = df[(df['Disaster Subtype'] == 'Flood') & (df['Total Affected'].notna()) & (df['Total Deaths'].notna()) & (df['Dis Mag Scale'].notna()) & (df['Dis Mag Value'].notna())]\n",
    "\n",
    "# # Limpiar y convertir la columna 'Latitude'\n",
    "# df_flood['Latitude'] = df_flood['Latitude'].astype(str).apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "# df_flood['Latitude'] = df_flood['Latitude'].str.rstrip('.')\n",
    "# df_flood['Latitude'] = df_flood['Latitude'].replace('', np.nan)\n",
    "# df_flood['Latitude'] = df_flood['Latitude'].astype(float)\n",
    "\n",
    "# # Limpiar y convertir la columna 'Longitude'\n",
    "# df_flood['Longitude'] = df_flood['Longitude'].astype(str).apply(lambda x: re.sub('[^\\d.-]', '', x.split('.', 1)[0]) if isinstance(x, str) else x)\n",
    "# df_flood['Longitude'] = df_flood['Longitude'].str.rstrip('.')\n",
    "# df_flood['Longitude'] = df_flood['Longitude'].replace('', np.nan)\n",
    "# df_flood['Longitude'] = df_flood['Longitude'].astype(float)\n",
    "\n",
    "# # Remover filas con NaN en coordenadas, 'Total Deaths', y 'Total Affected'\n",
    "# df_flood = df_flood.dropna(subset=['Latitude', 'Longitude', 'Total Deaths', 'Total Affected'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de verificación de limpieza de coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12       NaN\n",
      "13       NaN\n",
      "34       NaN\n",
      "39       NaN\n",
      "43       NaN\n",
      "        ... \n",
      "16620    NaN\n",
      "16628    NaN\n",
      "16629    NaN\n",
      "16631    NaN\n",
      "16634    NaN\n",
      "Name: Latitude, Length: 5808, dtype: object\n",
      "12       NaN\n",
      "13       NaN\n",
      "34       NaN\n",
      "39       NaN\n",
      "43       NaN\n",
      "        ... \n",
      "16620    NaN\n",
      "16628    NaN\n",
      "16629    NaN\n",
      "16631    NaN\n",
      "16634    NaN\n",
      "Name: Longitude, Length: 5808, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_flood['Latitude'])\n",
    "print(df_flood['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df_flood['Latitude'].dtype)\n",
    "print(df_flood['Longitude'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.379\n",
      "110.24\n"
     ]
    }
   ],
   "source": [
    "# Examinar filas específicas para verificar si el proceso de limpieza ha manejado los valores anómalos correctamente.\n",
    "print(df_flood.loc[12000, 'Latitude'])\n",
    "print(df_flood.loc[12000, 'Longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores Anómalos de Latitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anomalous_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anomalous_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Índices Anómalos de Latitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índices Anómalos de Latitud: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157]\n"
     ]
    }
   ],
   "source": [
    "anomalous_lat_idx = []\n",
    "for index, lat in enumerate(anomalous_lat):\n",
    "    if lat < -90 or lat > 90:\n",
    "        anomalous_lat_idx.append(index)\n",
    "\n",
    "print(\"Índices Anómalos de Latitud:\", anomalous_lat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índices Anómalos de Longitud: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "anomalous_lon_idx = []\n",
    "for index, lon in enumerate(anomalous_lon):\n",
    "    if lat < -90 or lat > 90:\n",
    "        anomalous_lon_idx.append(index)\n",
    "\n",
    "print(\"Índices Anómalos de Longitud:\", anomalous_lon_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers de Latitude y Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sns\u001b[39m.\u001b[39;49mboxplot(df_flood[\u001b[39m'\u001b[39;49m\u001b[39mLongitude\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:2231\u001b[0m, in \u001b[0;36mboxplot\u001b[1;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth, whis, ax, **kwargs)\u001b[0m\n\u001b[0;32m   2224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mboxplot\u001b[39m(\n\u001b[0;32m   2225\u001b[0m     data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, hue\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, hue_order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2226\u001b[0m     orient\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, color\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, saturation\u001b[39m=\u001b[39m\u001b[39m.75\u001b[39m, width\u001b[39m=\u001b[39m\u001b[39m.8\u001b[39m,\n\u001b[0;32m   2227\u001b[0m     dodge\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fliersize\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, whis\u001b[39m=\u001b[39m\u001b[39m1.5\u001b[39m, ax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2228\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   2229\u001b[0m ):\n\u001b[1;32m-> 2231\u001b[0m     plotter \u001b[39m=\u001b[39m _BoxPlotter(x, y, hue, data, order, hue_order,\n\u001b[0;32m   2232\u001b[0m                           orient, color, palette, saturation,\n\u001b[0;32m   2233\u001b[0m                           width, dodge, fliersize, linewidth)\n\u001b[0;32m   2235\u001b[0m     \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2236\u001b[0m         ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgca()\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:785\u001b[0m, in \u001b[0;36m_BoxPlotter.__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[0;32m    782\u001b[0m              orient, color, palette, saturation,\n\u001b[0;32m    783\u001b[0m              width, dodge, fliersize, linewidth):\n\u001b[1;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestablish_variables(x, y, hue, data, orient, order, hue_order)\n\u001b[0;32m    786\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[0;32m    788\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdodge \u001b[39m=\u001b[39m dodge\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:486\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 486\u001b[0m         \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misscalar(data[\u001b[39m0\u001b[39;49m]):\n\u001b[0;32m    487\u001b[0m             plot_data \u001b[39m=\u001b[39m [data]\n\u001b[0;32m    488\u001b[0m         \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "sns.boxplot(df_flood['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sns\u001b[39m.\u001b[39;49mboxplot(df_flood[\u001b[39m'\u001b[39;49m\u001b[39mLatitude\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:2231\u001b[0m, in \u001b[0;36mboxplot\u001b[1;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth, whis, ax, **kwargs)\u001b[0m\n\u001b[0;32m   2224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mboxplot\u001b[39m(\n\u001b[0;32m   2225\u001b[0m     data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, hue\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, hue_order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2226\u001b[0m     orient\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, color\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, saturation\u001b[39m=\u001b[39m\u001b[39m.75\u001b[39m, width\u001b[39m=\u001b[39m\u001b[39m.8\u001b[39m,\n\u001b[0;32m   2227\u001b[0m     dodge\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fliersize\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, whis\u001b[39m=\u001b[39m\u001b[39m1.5\u001b[39m, ax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2228\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   2229\u001b[0m ):\n\u001b[1;32m-> 2231\u001b[0m     plotter \u001b[39m=\u001b[39m _BoxPlotter(x, y, hue, data, order, hue_order,\n\u001b[0;32m   2232\u001b[0m                           orient, color, palette, saturation,\n\u001b[0;32m   2233\u001b[0m                           width, dodge, fliersize, linewidth)\n\u001b[0;32m   2235\u001b[0m     \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2236\u001b[0m         ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgca()\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:785\u001b[0m, in \u001b[0;36m_BoxPlotter.__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[0;32m    782\u001b[0m              orient, color, palette, saturation,\n\u001b[0;32m    783\u001b[0m              width, dodge, fliersize, linewidth):\n\u001b[1;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestablish_variables(x, y, hue, data, orient, order, hue_order)\n\u001b[0;32m    786\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[0;32m    788\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdodge \u001b[39m=\u001b[39m dodge\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\categorical.py:486\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 486\u001b[0m         \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misscalar(data[\u001b[39m0\u001b[39;49m]):\n\u001b[0;32m    487\u001b[0m             plot_data \u001b[39m=\u001b[39m [data]\n\u001b[0;32m    488\u001b[0m         \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "sns.boxplot(df_flood['Latitude'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Longitude', 'Latitude']].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afectados por Inundaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood['Total Deaths'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood['Total Affected'].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood.groupby('Country')['Total Deaths'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_deaths_by_continent = df_flood.groupby('Continent')['Total Deaths'].sum().to_frame()\n",
    "total_deaths_by_continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_deaths_by_region = df_flood.groupby('Continent')['Total Deaths'].sum().to_frame()\n",
    "total_deaths_by_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_deaths_by_country = df_flood.groupby('Country')['Total Deaths'].value_counts()\n",
    "total_deaths_by_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood[['Longitude', 'Latitude', 'Country']].reset_index().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,8), dpi=300)\n",
    "# sns.swarmplot(data=df_flood, x='Longitude', y= 'Latitude', hue= 'Continent', palette='Paired', size='Total Deaths', sizes=(20,200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
