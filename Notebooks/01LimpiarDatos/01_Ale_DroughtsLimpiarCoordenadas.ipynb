{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiar Coordenadas para Drought"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.impute import SimpleImputer\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"MozillaFirefox\", timeout=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar base de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03desastreslimpio.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Region</th>\n",
       "      <th>Continent</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Total Damages Adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-9002-CPV</td>\n",
       "      <td>1900</td>\n",
       "      <td>9002</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Cabo Verde</td>\n",
       "      <td>CPV</td>\n",
       "      <td>Western Africa</td>\n",
       "      <td>Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900-9001-IND</td>\n",
       "      <td>1900</td>\n",
       "      <td>9001</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1902-0012-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>12</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>GTM</td>\n",
       "      <td>Central America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>-91</td>\n",
       "      <td>1902</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1902</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>843726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1902-0003-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>3</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>GTM</td>\n",
       "      <td>Central America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1902</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1902</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902-0010-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>10</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>GTM</td>\n",
       "      <td>Central America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1902</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>1902</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1903-0006-CAN</td>\n",
       "      <td>1903</td>\n",
       "      <td>6</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Mass movement (dry)</td>\n",
       "      <td>Rockfall</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1903</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1903</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>76</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1903-0012-COM</td>\n",
       "      <td>1903</td>\n",
       "      <td>12</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>Comoros (the)</td>\n",
       "      <td>COM</td>\n",
       "      <td>Eastern Africa</td>\n",
       "      <td>Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904-0003-BGD</td>\n",
       "      <td>1904</td>\n",
       "      <td>3</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BGD</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1904</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1904</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1905-0005-CAN</td>\n",
       "      <td>1905</td>\n",
       "      <td>5</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Mass movement (dry)</td>\n",
       "      <td>Rockfall</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1905</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1905</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1905-0003-IND</td>\n",
       "      <td>1905</td>\n",
       "      <td>3</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>76.16</td>\n",
       "      <td>1905</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1905</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>812477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dis No  Year   Seq Disaster Subgroup        Disaster Type  \\\n",
       "0  1900-9002-CPV  1900  9002    Climatological              Drought   \n",
       "1  1900-9001-IND  1900  9001    Climatological              Drought   \n",
       "2  1902-0012-GTM  1902    12       Geophysical           Earthquake   \n",
       "3  1902-0003-GTM  1902     3       Geophysical    Volcanic activity   \n",
       "4  1902-0010-GTM  1902    10       Geophysical    Volcanic activity   \n",
       "5  1903-0006-CAN  1903     6       Geophysical  Mass movement (dry)   \n",
       "6  1903-0012-COM  1903    12       Geophysical    Volcanic activity   \n",
       "7  1904-0003-BGD  1904     3    Meteorological                Storm   \n",
       "8  1905-0005-CAN  1905     5       Geophysical  Mass movement (dry)   \n",
       "9  1905-0003-IND  1905     3       Geophysical           Earthquake   \n",
       "\n",
       "   Disaster Subtype        Country  ISO            Region Continent  ...  \\\n",
       "0           Drought     Cabo Verde  CPV    Western Africa    Africa  ...   \n",
       "1           Drought          India  IND     Southern Asia      Asia  ...   \n",
       "2   Ground movement      Guatemala  GTM   Central America  Americas  ...   \n",
       "3          Ash fall      Guatemala  GTM   Central America  Americas  ...   \n",
       "4          Ash fall      Guatemala  GTM   Central America  Americas  ...   \n",
       "5          Rockfall         Canada  CAN  Northern America  Americas  ...   \n",
       "6          Ash fall  Comoros (the)  COM    Eastern Africa    Africa  ...   \n",
       "7  Tropical cyclone     Bangladesh  BGD     Southern Asia      Asia  ...   \n",
       "8          Rockfall         Canada  CAN  Northern America  Americas  ...   \n",
       "9   Ground movement          India  IND     Southern Asia      Asia  ...   \n",
       "\n",
       "  Longitude Start Year Start Month  Start Day End Year End Month End Day  \\\n",
       "0       NaN       1900           0          0     1900         0       0   \n",
       "1       NaN       1900           0          0     1900         0       0   \n",
       "2       -91       1902           4         18     1902         4      18   \n",
       "3       NaN       1902           4          8     1902         4       8   \n",
       "4       NaN       1902          10         24     1902        10      24   \n",
       "5       NaN       1903           4         29     1903         4      29   \n",
       "6       NaN       1903           0          0     1903         0       0   \n",
       "7       NaN       1904          11          0     1904        11       0   \n",
       "8       NaN       1905           8         13     1905         8      13   \n",
       "9     76.16       1905           4          4     1905         4       4   \n",
       "\n",
       "   Total Deaths  Total Affected  Total Damages Adj  \n",
       "0         11000               0                  0  \n",
       "1       1250000               0                  0  \n",
       "2          2000               0             843726  \n",
       "3          1000               0                  0  \n",
       "4          6000               0                  0  \n",
       "5            76              23                  0  \n",
       "6            17               0                  0  \n",
       "7             0               0                  0  \n",
       "8            18              18                  0  \n",
       "9         20000               0             812477  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../Data/03Limpio/03desastreslimpio.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Inicial B√°sico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16636, 26)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16636 entries, 0 to 16635\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Dis No             16636 non-null  object\n",
      " 1   Year               16636 non-null  int64 \n",
      " 2   Seq                16636 non-null  int64 \n",
      " 3   Disaster Subgroup  16636 non-null  object\n",
      " 4   Disaster Type      16636 non-null  object\n",
      " 5   Disaster Subtype   13313 non-null  object\n",
      " 6   Country            16636 non-null  object\n",
      " 7   ISO                16636 non-null  object\n",
      " 8   Region             16636 non-null  object\n",
      " 9   Continent          16636 non-null  object\n",
      " 10  Location           14825 non-null  object\n",
      " 11  Origin             4085 non-null   object\n",
      " 12  Associated Dis     3593 non-null   object\n",
      " 13  Dis Mag Value      16636 non-null  int64 \n",
      " 14  Dis Mag Scale      15416 non-null  object\n",
      " 15  Latitude           2775 non-null   object\n",
      " 16  Longitude          2775 non-null   object\n",
      " 17  Start Year         16636 non-null  int64 \n",
      " 18  Start Month        16636 non-null  int64 \n",
      " 19  Start Day          16636 non-null  int64 \n",
      " 20  End Year           16636 non-null  int64 \n",
      " 21  End Month          16636 non-null  int64 \n",
      " 22  End Day            16636 non-null  int64 \n",
      " 23  Total Deaths       16636 non-null  int64 \n",
      " 24  Total Affected     16636 non-null  int64 \n",
      " 25  Total Damages Adj  16636 non-null  int64 \n",
      "dtypes: int64(12), object(14)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro Disaster Type == Drought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = df['Disaster Type'] == 'Drought'\n",
    "df_drought = df[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Region</th>\n",
       "      <th>Continent</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Total Damages Adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-9002-CPV</td>\n",
       "      <td>1900</td>\n",
       "      <td>9002</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Cabo Verde</td>\n",
       "      <td>CPV</td>\n",
       "      <td>Western Africa</td>\n",
       "      <td>Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900-9001-IND</td>\n",
       "      <td>1900</td>\n",
       "      <td>9001</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dis No  Year   Seq Disaster Subgroup Disaster Type Disaster Subtype  \\\n",
       "0  1900-9002-CPV  1900  9002    Climatological       Drought          Drought   \n",
       "1  1900-9001-IND  1900  9001    Climatological       Drought          Drought   \n",
       "\n",
       "      Country  ISO          Region Continent  ... Longitude Start Year  \\\n",
       "0  Cabo Verde  CPV  Western Africa    Africa  ...       NaN       1900   \n",
       "1       India  IND   Southern Asia      Asia  ...       NaN       1900   \n",
       "\n",
       "  Start Month  Start Day End Year End Month End Day  Total Deaths  \\\n",
       "0           0          0     1900         0       0         11000   \n",
       "1           0          0     1900         0       0       1250000   \n",
       "\n",
       "   Total Affected  Total Damages Adj  \n",
       "0               0                  0  \n",
       "1               0                  0  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drought.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(803, 26)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drought.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drought['Disaster Type'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drought['Latitude'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drought['Longitude'].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de coordenadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funci√≥n para limpiar coordenadas filtrado para df_drought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_7104\\295546297.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drought['Latitude'] = df_drought['Latitude'].astype(str)\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_7104\\295546297.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drought['Longitude'] = df_drought['Longitude'].astype(str)\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_7104\\295546297.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drought['Latitude'] = df_drought['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_7104\\295546297.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drought['Longitude'] = df_drought['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_7104\\295546297.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drought['Latitude'] = df_drought['Latitude'].str.rstrip('.')\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_7104\\295546297.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drought['Longitude'] = df_drought['Longitude'].str.rstrip('.')\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_7104\\295546297.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drought['Latitude'] = df_drought['Latitude'].apply(convert_coordinates)\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_7104\\295546297.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drought['Longitude'] = df_drought['Longitude'].apply(convert_coordinates)\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_7104\\295546297.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drought['Latitude'] = df_drought['Latitude'].round(2)\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_7104\\295546297.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_drought['Longitude'] = df_drought['Longitude'].round(2)\n"
     ]
    }
   ],
   "source": [
    "# Initializar geolocator\n",
    "geolocator = Nominatim(user_agent=\"eqlimpiarcoord\")\n",
    "\n",
    "# Convertir 'Latitude' y 'Longitude' a string\n",
    "df_drought['Latitude'] = df_drought['Latitude'].astype(str)\n",
    "df_drought['Longitude'] = df_drought['Longitude'].astype(str)\n",
    "\n",
    "# Limpiar coordenadas de latitude y longitude\n",
    "df_drought['Latitude'] = df_drought['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
    "df_drought['Longitude'] = df_drought['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
    "\n",
    "# Remover puntos finales\n",
    "df_drought['Latitude'] = df_drought['Latitude'].str.rstrip('.')\n",
    "df_drought['Longitude'] = df_drought['Longitude'].str.rstrip('.')\n",
    "\n",
    "# A√±adir valores an√≥malos de latitud y longitud a listas\n",
    "anomalous_lat = []\n",
    "anomalous_lon = []\n",
    "\n",
    "# Funci√≥n para convertir coordenadas y detectar anomal√≠as\n",
    "def convert_coordinates(x, convert_nan=True):\n",
    "    if not x:\n",
    "        return np.nan\n",
    "\n",
    "    # Remover caracteres 'N' y 'E'\n",
    "    x = x.replace(' N', '').replace(' E', '')\n",
    "\n",
    "    # Remover puntos extra en decimales\n",
    "    x = re.sub('^(\\d+\\.\\d{2})\\..*', r'\\1', x)\n",
    "\n",
    "    # Conversi√≥n a negativo para S y W\n",
    "    try:\n",
    "        value = float(x)\n",
    "        if x[-1] == 'S' or x[-1] == 'W':\n",
    "            return -value\n",
    "        else:\n",
    "            return value\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# Convertir a float\n",
    "df_drought['Latitude'] = df_drought['Latitude'].apply(convert_coordinates)\n",
    "df_drought['Longitude'] = df_drought['Longitude'].apply(convert_coordinates)\n",
    "\n",
    "# Redondear decimales\n",
    "df_drought['Latitude'] = df_drought['Latitude'].round(2)\n",
    "df_drought['Longitude'] = df_drought['Longitude'].round(2)\n",
    "\n",
    "# Identificar valores an√≥malos de latitude y longitude\n",
    "for index, row in df_drought.iterrows():\n",
    "    latitude = row['Latitude']\n",
    "    longitude = row['Longitude']\n",
    "\n",
    "    if latitude < -90 or latitude > 90:\n",
    "        anomalous_lat.append(index)\n",
    "\n",
    "    if longitude < -180 or longitude > 180:\n",
    "        anomalous_lon.append(index)\n",
    "\n",
    "# Revisar inconsistencias de cantidad entre an√≥malos de latitude y longitude\n",
    "if len(anomalous_lat) != len(anomalous_lon):\n",
    "    print(\"Valores inconsistentes de latitud y longitud.\")\n",
    "    # Gestionar la inconsistencia, como remover los valores extras o ajustar las listas\n",
    "    # Por ejemplo, remover los valores extra de latitud:\n",
    "    anomalous_lat = anomalous_lat[:len(anomalous_lon)]\n",
    "    print(\"Longitud de latitud an√≥mala ajustada:\", len(anomalous_lat))\n",
    "\n",
    "# Crear nuevo DataFrame con coordenadas limpias y emparejadas\n",
    "df_drcleaned = df_drought.copy()\n",
    "\n",
    "# Funci√≥n para rellenar coordenadas an√≥malas usando geocoding\n",
    "def fill_anomalous_coordinates(row):\n",
    "    if row.name in anomalous_lat and row.name in anomalous_lon:\n",
    "        try:\n",
    "            location = geolocator.reverse((row['Latitude'], row['Longitude']), timeout=10)\n",
    "            if location and location.latitude is not None and location.longitude is not None:\n",
    "                row['Latitude'] = location.latitude\n",
    "                row['Longitude'] = location.longitude\n",
    "                row['Location'] = location.address\n",
    "                row['Country'] = location.raw['address'].get('country')\n",
    "        except:\n",
    "            pass\n",
    "    return row\n",
    "\n",
    "# Rellenar coordenadas an√≥malas\n",
    "df_drcleaned = df_drcleaned.apply(fill_anomalous_coordinates, axis=1)\n",
    "\n",
    "# Borrar filas con location y country no emparejadas\n",
    "df_drcleaned = df_drcleaned[~((df_drcleaned['Latitude'].isin(anomalous_lat)) & (df_drcleaned['Longitude'].isin(anomalous_lon)))]\n",
    "\n",
    "# Borrar filas con valores null o nan en columnas de Latitud y Longitud\n",
    "df_drcleaned = df_drcleaned.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "# Convertir Latitud y Longitud a float con 2 decimales\n",
    "df_drcleaned['Latitude'] = df_drcleaned['Latitude'].astype(float).round(2)\n",
    "df_drcleaned['Longitude'] = df_drcleaned['Longitude'].astype(float).round(2)\n",
    "\n",
    "# # Exportar el DataFrame limpio a archivo\n",
    "# df_drcleaned.to_csv('droughtfilteredcleanedgeoloc.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Definimos la funci√≥n fill_anomalous_latlon que toma una fila como entrada. Si los valores de latitud y longitud de la fila se encuentran en las listas anomalous_lat y anomalous_lon, respectivamente, la funci√≥n intenta geocodificar la ubicaci√≥n mediante la columna Location o la columna Country. Si se encuentra una ubicaci√≥n v√°lida, se actualizan los valores de latitud y longitud de la fila.\n",
    "\n",
    "2. La llamada a la funci√≥n sleep(1) agrega un retraso de 1 segundo entre las solicitudes de geolocalizaci√≥n para cumplir con la pol√≠tica de uso del servicio de geocodificaci√≥n.\n",
    "\n",
    "3. Luego creamos un objeto geolocalizador utilizando el geocodificador Nominatim de la biblioteca geopy.\n",
    "\n",
    "4. Finalmente, aplicamos la funci√≥n fill_anomalous_latlon a cada fila del DataFrame usando el m√©todo apply con axis=1, lo que indica que la funci√≥n debe aplicarse por filas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funci√≥n con geopy para limpiar coordenadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de verificaci√≥n de limpieza de coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13770</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Bahr El Ghazal, Northern Bahr El Ghaza...</td>\n",
       "      <td>South Sudan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13795</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baucau, Lautem, Viqueque provinces</td>\n",
       "      <td>Timor-Leste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13820</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yap, Chuuk regions</td>\n",
       "      <td>Micronesia (Federated States of)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13864</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seven provinces in the South (Cunene, Huila, N...</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13912</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northeast China, North China Plain, Inner Mong...</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16438</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Napak, Kaabong, Kotido, Moroto districts (Kara...</td>\n",
       "      <td>Uganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16449</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emilie-Romagne, Frioul-Venetie Julienne, Lomba...</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16472</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16479</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Malawi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16486</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Latitude  Longitude                                           Location  \\\n",
       "13770       NaN        NaN  Western Bahr El Ghazal, Northern Bahr El Ghaza...   \n",
       "13795       NaN        NaN                 Baucau, Lautem, Viqueque provinces   \n",
       "13820       NaN        NaN                                 Yap, Chuuk regions   \n",
       "13864       NaN        NaN  Seven provinces in the South (Cunene, Huila, N...   \n",
       "13912       NaN        NaN  Northeast China, North China Plain, Inner Mong...   \n",
       "...         ...        ...                                                ...   \n",
       "16438       NaN        NaN  Napak, Kaabong, Kotido, Moroto districts (Kara...   \n",
       "16449       NaN        NaN  Emilie-Romagne, Frioul-Venetie Julienne, Lomba...   \n",
       "16472       NaN        NaN                                                NaN   \n",
       "16479       NaN        NaN                                                NaN   \n",
       "16486       NaN        NaN                                                NaN   \n",
       "\n",
       "                                Country  \n",
       "13770                       South Sudan  \n",
       "13795                       Timor-Leste  \n",
       "13820  Micronesia (Federated States of)  \n",
       "13864                            Angola  \n",
       "13912                             China  \n",
       "...                                 ...  \n",
       "16438                            Uganda  \n",
       "16449                             Italy  \n",
       "16472                              Mali  \n",
       "16479                            Malawi  \n",
       "16486                           Nigeria  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drought[['Latitude', 'Longitude', 'Location', 'Country']][700:800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Filtrar DataFrame para detectar valores an√≥malos de latitud y longitud\n",
    "df_eqanomalous = df_drought[\n",
    "    df_drought['Latitude'].isin(anomalous_lat) | df_drought['Longitude'].isin(anomalous_lon)\n",
    "]\n",
    "\n",
    "# Crear pivot table para comparar las columnas de latitude, longitude, location, y country\n",
    "df_eqanomalous_pivot = df_eqanomalous.pivot_table(\n",
    "    index=['Location', 'Country'],\n",
    "    values=['Latitude', 'Longitude'],\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "# Mostrar la pivot table\n",
    "print(df_eqanomalous_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       NaN\n",
      "1       NaN\n",
      "24      NaN\n",
      "27      NaN\n",
      "30      NaN\n",
      "         ..\n",
      "16479   NaN\n",
      "16486   NaN\n",
      "16506   NaN\n",
      "16534   NaN\n",
      "16557   NaN\n",
      "Name: Latitude, Length: 803, dtype: float64\n",
      "0       NaN\n",
      "1       NaN\n",
      "24      NaN\n",
      "27      NaN\n",
      "30      NaN\n",
      "         ..\n",
      "16479   NaN\n",
      "16486   NaN\n",
      "16506   NaN\n",
      "16534   NaN\n",
      "16557   NaN\n",
      "Name: Longitude, Length: 803, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_drought['Latitude'])\n",
    "print(df_drought['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(df_drought['Latitude'].dtype)\n",
    "print(df_drought['Longitude'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Examinar filas espec√≠ficas para verificar si el proceso de limpieza ha manejado los valores an√≥malos correctamente.\n",
    "# print(df_drought.loc[6000, 'Latitude'])\n",
    "# print(df_drought.loc[6000, 'Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Longitude    803\n",
       "Latitude     803\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores nulos de Longitude y Latitude\n",
    "df_drought[['Longitude', 'Latitude']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores An√≥malos de Latitud y Longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anomalous_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anomalous_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### √çndices An√≥malos de Latitud y longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√çndices An√≥malos de Latitud: []\n"
     ]
    }
   ],
   "source": [
    "anomalous_lat_idx = []\n",
    "for index, lat in enumerate(anomalous_lat):\n",
    "    if lat < -90 or lat > 90:\n",
    "        anomalous_lat_idx.append(index)\n",
    "\n",
    "print(\"√çndices An√≥malos de Latitud:\", anomalous_lat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√çndices An√≥malos de Longitud: []\n"
     ]
    }
   ],
   "source": [
    "anomalous_lon_idx = []\n",
    "for index, lon in enumerate(anomalous_lon):\n",
    "    if lat < -90 or lat > 90:\n",
    "        anomalous_lon_idx.append(index)\n",
    "\n",
    "print(\"√çndices An√≥malos de Longitud:\", anomalous_lon_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers de Latitude y Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(df_drought['Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(df_drought['Longitude'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 803 entries, 0 to 16557\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Dis No             803 non-null    object \n",
      " 1   Year               803 non-null    int64  \n",
      " 2   Seq                803 non-null    int64  \n",
      " 3   Disaster Subgroup  803 non-null    object \n",
      " 4   Disaster Type      803 non-null    object \n",
      " 5   Disaster Subtype   802 non-null    object \n",
      " 6   Country            803 non-null    object \n",
      " 7   ISO                803 non-null    object \n",
      " 8   Region             803 non-null    object \n",
      " 9   Continent          803 non-null    object \n",
      " 10  Location           632 non-null    object \n",
      " 11  Origin             165 non-null    object \n",
      " 12  Associated Dis     290 non-null    object \n",
      " 13  Dis Mag Value      803 non-null    int64  \n",
      " 14  Dis Mag Scale      803 non-null    object \n",
      " 15  Latitude           0 non-null      float64\n",
      " 16  Longitude          0 non-null      float64\n",
      " 17  Start Year         803 non-null    int64  \n",
      " 18  Start Month        803 non-null    int64  \n",
      " 19  Start Day          803 non-null    int64  \n",
      " 20  End Year           803 non-null    int64  \n",
      " 21  End Month          803 non-null    int64  \n",
      " 22  End Day            803 non-null    int64  \n",
      " 23  Total Deaths       803 non-null    int64  \n",
      " 24  Total Affected     803 non-null    int64  \n",
      " 25  Total Damages Adj  803 non-null    int64  \n",
      "dtypes: float64(2), int64(12), object(12)\n",
      "memory usage: 169.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_drought.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dis No                 0\n",
       "Year                   0\n",
       "Seq                    0\n",
       "Disaster Subgroup      0\n",
       "Disaster Type          0\n",
       "Disaster Subtype       1\n",
       "Country                0\n",
       "ISO                    0\n",
       "Region                 0\n",
       "Continent              0\n",
       "Location             171\n",
       "Origin               638\n",
       "Associated Dis       513\n",
       "Dis Mag Value          0\n",
       "Dis Mag Scale          0\n",
       "Latitude             803\n",
       "Longitude            803\n",
       "Start Year             0\n",
       "Start Month            0\n",
       "Start Day              0\n",
       "End Year               0\n",
       "End Month              0\n",
       "End Day                0\n",
       "Total Deaths           0\n",
       "Total Affected         0\n",
       "Total Damages Adj      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drought.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputar valores an√≥malos con SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m anomalous_lat_to_impute \u001b[39m=\u001b[39m df_drought[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(anomalous_lat)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Imputar los valores con la media a anomalous_lon en 'Longitude'\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df_drought\u001b[39m.\u001b[39;49mloc[anomalous_lat_to_impute, \u001b[39m'\u001b[39;49m\u001b[39mLatitude\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m imputer\u001b[39m.\u001b[39mfit_transform(df_drought[[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m]])[anomalous_lat_to_impute]\n\u001b[0;32m      8\u001b[0m df_drought[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[0;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1794\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1795\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1796\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1797\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1834\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1831\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_with_indexer_frame_value(indexer, value, name)\n\u001b[0;32m   1833\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39mndim(value) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 1834\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_2d_value(indexer, value)\n\u001b[0;32m   1836\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(ilocs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m lplane_indexer \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(value) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(pi):\n\u001b[0;32m   1837\u001b[0m     \u001b[39m# We are setting multiple rows in a single column.\u001b[39;00m\n\u001b[0;32m   1838\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_column(ilocs[\u001b[39m0\u001b[39m], value, pi)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1900\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_2d_value\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1898\u001b[0m value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(value, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m)\n\u001b[0;32m   1899\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ilocs) \u001b[39m!=\u001b[39m value\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m-> 1900\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1901\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMust have equal len keys and value when setting with an ndarray\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1902\u001b[0m     )\n\u001b[0;32m   1904\u001b[0m \u001b[39mfor\u001b[39;00m i, loc \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(ilocs):\n\u001b[0;32m   1905\u001b[0m     \u001b[39m# setting with a list, re-coerces\u001b[39;00m\n\u001b[0;32m   1906\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_column(loc, value[:, i]\u001b[39m.\u001b[39mtolist(), pi)\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "# imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# # Seleccionar filas donde 'Longitude' est√° (isin) la lista de anomalous_lon\n",
    "# anomalous_lat_to_impute = df_drought['Latitude'].isin(anomalous_lat)\n",
    "\n",
    "# # Imputar los valores con la media a anomalous_lon en 'Longitude'\n",
    "# df_drought.loc[anomalous_lat_to_impute, 'Latitude'] = imputer.fit_transform(df_drought[['Latitude']])[anomalous_lat_to_impute]\n",
    "# df_drought['Latitude'].isnull().sum()\n",
    "\n",
    "# No permite imputar. ValueError: Must have equal len keys and value when setting with an ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m anomalous_lon_to_impute \u001b[39m=\u001b[39m df_drought[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(anomalous_lon)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Imputar los valores an√≥malos con la media a anomalous_lon en 'Longitude'\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df_drought\u001b[39m.\u001b[39;49mloc[anomalous_lon_to_impute, \u001b[39m'\u001b[39;49m\u001b[39mLongitude\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m imputer\u001b[39m.\u001b[39mfit_transform(df_drought[[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]])[anomalous_lon_to_impute]\n\u001b[0;32m      8\u001b[0m df_drought[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[0;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1794\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1795\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1796\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1797\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1834\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1831\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_with_indexer_frame_value(indexer, value, name)\n\u001b[0;32m   1833\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39mndim(value) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 1834\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_2d_value(indexer, value)\n\u001b[0;32m   1836\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(ilocs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m lplane_indexer \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(value) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(pi):\n\u001b[0;32m   1837\u001b[0m     \u001b[39m# We are setting multiple rows in a single column.\u001b[39;00m\n\u001b[0;32m   1838\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_column(ilocs[\u001b[39m0\u001b[39m], value, pi)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1900\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_2d_value\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1898\u001b[0m value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(value, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m)\n\u001b[0;32m   1899\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ilocs) \u001b[39m!=\u001b[39m value\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m-> 1900\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1901\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMust have equal len keys and value when setting with an ndarray\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1902\u001b[0m     )\n\u001b[0;32m   1904\u001b[0m \u001b[39mfor\u001b[39;00m i, loc \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(ilocs):\n\u001b[0;32m   1905\u001b[0m     \u001b[39m# setting with a list, re-coerces\u001b[39;00m\n\u001b[0;32m   1906\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_column(loc, value[:, i]\u001b[39m.\u001b[39mtolist(), pi)\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "# imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# # Seleccionar filas donde 'Longitude' est√° (isin) la lista de anomalous_lon\n",
    "# anomalous_lon_to_impute = df_drought['Longitude'].isin(anomalous_lon)\n",
    "\n",
    "# # Imputar los valores an√≥malos con la media a anomalous_lon en 'Longitude'\n",
    "# df_drought.loc[anomalous_lon_to_impute, 'Longitude'] = imputer.fit_transform(df_drought[['Longitude']])[anomalous_lon_to_impute]\n",
    "# df_drought['Longitude'].isnull()\n",
    "\n",
    "# No permite imputar. ValueError: Must have equal len keys and value when setting with an ndarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputar mediana a nulos con SimpleImputer a Longitude y Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "# Seleccionar filas donde 'Longitude' sea null (NaN)\n",
    "null_lon_rows = df_drought['Latitude'].isnull()\n",
    "# Imputar los nulls en 'Longitude' estrategia mean\n",
    "df_drought.loc[null_lon_rows, 'Latitude'] = imputer.fit_transform(df_drought[['Latitude']])[null_lon_rows]\n",
    "df_drought['Latitude'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "# Seleccionar filas donde 'Longitude' sea null (NaN)\n",
    "null_lon_rows = df_drought['Longitude'].isnull()\n",
    "# Imputar los nulls en 'Longitude' estrategia mean\n",
    "df_drought.loc[null_lon_rows, 'Longitude'] = imputer.fit_transform(df_drought[['Longitude']])[null_lon_rows]\n",
    "df_drought['Longitude'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drought.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drought_origin_geolocation_pivot = df_drought.pivot_table(\n",
    "    index='Origin',\n",
    "    columns='Disaster Subtype',\n",
    "    values=['Latitude', 'Longitude', 'Location'],\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "df_drought_origin_geolocation_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drought_year_geolocation_pivot = df_drought.pivot_table(\n",
    "    index='Year',\n",
    "    columns='Disaster Subtype',\n",
    "    values=['Latitude', 'Longitude', 'Location'],\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "df_drought_year_geolocation_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar dataset Drought limpio en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../Data/03Limpio/DroughtLimpioCSV/03desastres_4droughtcoordlimpias.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
