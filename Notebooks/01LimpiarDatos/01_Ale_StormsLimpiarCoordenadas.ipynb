{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiar Coordenadas para Storm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.impute import SimpleImputer\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"MozillaFirefox\", timeout=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar base de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03desastreslimpio.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Region</th>\n",
       "      <th>Continent</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Total Damages Adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-9002-CPV</td>\n",
       "      <td>1900</td>\n",
       "      <td>9002</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Cabo Verde</td>\n",
       "      <td>CPV</td>\n",
       "      <td>Western Africa</td>\n",
       "      <td>Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900-9001-IND</td>\n",
       "      <td>1900</td>\n",
       "      <td>9001</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1902-0012-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>12</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>GTM</td>\n",
       "      <td>Central America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>-91</td>\n",
       "      <td>1902</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1902</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>843726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1902-0003-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>3</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>GTM</td>\n",
       "      <td>Central America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1902</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1902</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902-0010-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>10</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>GTM</td>\n",
       "      <td>Central America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1902</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>1902</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1903-0006-CAN</td>\n",
       "      <td>1903</td>\n",
       "      <td>6</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Mass movement (dry)</td>\n",
       "      <td>Rockfall</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1903</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1903</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>76</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1903-0012-COM</td>\n",
       "      <td>1903</td>\n",
       "      <td>12</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>Comoros (the)</td>\n",
       "      <td>COM</td>\n",
       "      <td>Eastern Africa</td>\n",
       "      <td>Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904-0003-BGD</td>\n",
       "      <td>1904</td>\n",
       "      <td>3</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BGD</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1904</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1904</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1905-0005-CAN</td>\n",
       "      <td>1905</td>\n",
       "      <td>5</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Mass movement (dry)</td>\n",
       "      <td>Rockfall</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1905</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1905</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1905-0003-IND</td>\n",
       "      <td>1905</td>\n",
       "      <td>3</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>76.16</td>\n",
       "      <td>1905</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1905</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>812477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dis No  Year   Seq Disaster Subgroup        Disaster Type  \\\n",
       "0  1900-9002-CPV  1900  9002    Climatological              Drought   \n",
       "1  1900-9001-IND  1900  9001    Climatological              Drought   \n",
       "2  1902-0012-GTM  1902    12       Geophysical           Earthquake   \n",
       "3  1902-0003-GTM  1902     3       Geophysical    Volcanic activity   \n",
       "4  1902-0010-GTM  1902    10       Geophysical    Volcanic activity   \n",
       "5  1903-0006-CAN  1903     6       Geophysical  Mass movement (dry)   \n",
       "6  1903-0012-COM  1903    12       Geophysical    Volcanic activity   \n",
       "7  1904-0003-BGD  1904     3    Meteorological                Storm   \n",
       "8  1905-0005-CAN  1905     5       Geophysical  Mass movement (dry)   \n",
       "9  1905-0003-IND  1905     3       Geophysical           Earthquake   \n",
       "\n",
       "   Disaster Subtype        Country  ISO            Region Continent  ...  \\\n",
       "0           Drought     Cabo Verde  CPV    Western Africa    Africa  ...   \n",
       "1           Drought          India  IND     Southern Asia      Asia  ...   \n",
       "2   Ground movement      Guatemala  GTM   Central America  Americas  ...   \n",
       "3          Ash fall      Guatemala  GTM   Central America  Americas  ...   \n",
       "4          Ash fall      Guatemala  GTM   Central America  Americas  ...   \n",
       "5          Rockfall         Canada  CAN  Northern America  Americas  ...   \n",
       "6          Ash fall  Comoros (the)  COM    Eastern Africa    Africa  ...   \n",
       "7  Tropical cyclone     Bangladesh  BGD     Southern Asia      Asia  ...   \n",
       "8          Rockfall         Canada  CAN  Northern America  Americas  ...   \n",
       "9   Ground movement          India  IND     Southern Asia      Asia  ...   \n",
       "\n",
       "  Longitude Start Year Start Month  Start Day End Year End Month End Day  \\\n",
       "0       NaN       1900           0          0     1900         0       0   \n",
       "1       NaN       1900           0          0     1900         0       0   \n",
       "2       -91       1902           4         18     1902         4      18   \n",
       "3       NaN       1902           4          8     1902         4       8   \n",
       "4       NaN       1902          10         24     1902        10      24   \n",
       "5       NaN       1903           4         29     1903         4      29   \n",
       "6       NaN       1903           0          0     1903         0       0   \n",
       "7       NaN       1904          11          0     1904        11       0   \n",
       "8       NaN       1905           8         13     1905         8      13   \n",
       "9     76.16       1905           4          4     1905         4       4   \n",
       "\n",
       "   Total Deaths  Total Affected  Total Damages Adj  \n",
       "0         11000               0                  0  \n",
       "1       1250000               0                  0  \n",
       "2          2000               0             843726  \n",
       "3          1000               0                  0  \n",
       "4          6000               0                  0  \n",
       "5            76              23                  0  \n",
       "6            17               0                  0  \n",
       "7             0               0                  0  \n",
       "8            18              18                  0  \n",
       "9         20000               0             812477  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../Data/03Limpio/03desastreslimpio.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Inicial Básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16636, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16636 entries, 0 to 16635\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Dis No             16636 non-null  object\n",
      " 1   Year               16636 non-null  int64 \n",
      " 2   Seq                16636 non-null  int64 \n",
      " 3   Disaster Subgroup  16636 non-null  object\n",
      " 4   Disaster Type      16636 non-null  object\n",
      " 5   Disaster Subtype   13313 non-null  object\n",
      " 6   Country            16636 non-null  object\n",
      " 7   ISO                16636 non-null  object\n",
      " 8   Region             16636 non-null  object\n",
      " 9   Continent          16636 non-null  object\n",
      " 10  Location           14825 non-null  object\n",
      " 11  Origin             4085 non-null   object\n",
      " 12  Associated Dis     3593 non-null   object\n",
      " 13  Dis Mag Value      16636 non-null  int64 \n",
      " 14  Dis Mag Scale      15416 non-null  object\n",
      " 15  Latitude           2775 non-null   object\n",
      " 16  Longitude          2775 non-null   object\n",
      " 17  Start Year         16636 non-null  int64 \n",
      " 18  Start Month        16636 non-null  int64 \n",
      " 19  Start Day          16636 non-null  int64 \n",
      " 20  End Year           16636 non-null  int64 \n",
      " 21  End Month          16636 non-null  int64 \n",
      " 22  End Day            16636 non-null  int64 \n",
      " 23  Total Deaths       16636 non-null  int64 \n",
      " 24  Total Affected     16636 non-null  int64 \n",
      " 25  Total Damages Adj  16636 non-null  int64 \n",
      "dtypes: int64(12), object(14)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro Disaster Type == Storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = df['Disaster Type'] == 'Storm'\n",
    "df_storm = df[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Region</th>\n",
       "      <th>Continent</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Total Damages Adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904-0003-BGD</td>\n",
       "      <td>1904</td>\n",
       "      <td>3</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BGD</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1904</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1904</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1906-0015-HKG</td>\n",
       "      <td>1906</td>\n",
       "      <td>15</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>HKG</td>\n",
       "      <td>Eastern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1906</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1906</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>649981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dis No  Year  Seq Disaster Subgroup Disaster Type  \\\n",
       "7   1904-0003-BGD  1904    3    Meteorological         Storm   \n",
       "14  1906-0015-HKG  1906   15    Meteorological         Storm   \n",
       "\n",
       "    Disaster Subtype     Country  ISO         Region Continent  ... Longitude  \\\n",
       "7   Tropical cyclone  Bangladesh  BGD  Southern Asia      Asia  ...       NaN   \n",
       "14  Tropical cyclone   Hong Kong  HKG   Eastern Asia      Asia  ...       NaN   \n",
       "\n",
       "   Start Year Start Month  Start Day End Year End Month End Day  Total Deaths  \\\n",
       "7        1904          11          0     1904        11       0             0   \n",
       "14       1906           9          8     1906         9       8         10000   \n",
       "\n",
       "    Total Affected  Total Damages Adj  \n",
       "7                0                  0  \n",
       "14               0             649981  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4618, 26)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm['Disaster Type'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm['Latitude'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm['Longitude'].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de coordenadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para limpiar coordenadas filtrado para df_storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\1215225285.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_storm['Latitude'] = df_storm['Latitude'].astype(str)\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\1215225285.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_storm['Longitude'] = df_storm['Longitude'].astype(str)\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\1215225285.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_storm['Latitude'] = df_storm['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\1215225285.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_storm['Longitude'] = df_storm['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\1215225285.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_storm['Latitude'] = df_storm['Latitude'].str.rstrip('.')\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\1215225285.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_storm['Longitude'] = df_storm['Longitude'].str.rstrip('.')\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\1215225285.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_storm['Latitude'] = df_storm['Latitude'].apply(convert_coordinates)\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\1215225285.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_storm['Longitude'] = df_storm['Longitude'].apply(convert_coordinates)\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\1215225285.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_storm['Latitude'] = df_storm['Latitude'].round(2)\n",
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\1215225285.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_storm['Longitude'] = df_storm['Longitude'].round(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores inconsistentes de latitud y longitud.\n",
      "Longitud de latitud anómala ajustada: 0\n"
     ]
    }
   ],
   "source": [
    "# Initializar geolocator\n",
    "geolocator = Nominatim(user_agent=\"eqlimpiarcoord\")\n",
    "\n",
    "# Convertir 'Latitude' y 'Longitude' a string\n",
    "df_storm['Latitude'] = df_storm['Latitude'].astype(str)\n",
    "df_storm['Longitude'] = df_storm['Longitude'].astype(str)\n",
    "\n",
    "# Limpiar coordenadas de latitude y longitude\n",
    "df_storm['Latitude'] = df_storm['Latitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
    "df_storm['Longitude'] = df_storm['Longitude'].apply(lambda x: re.sub('[^\\d.-]', '', x))\n",
    "\n",
    "# Remover puntos finales\n",
    "df_storm['Latitude'] = df_storm['Latitude'].str.rstrip('.')\n",
    "df_storm['Longitude'] = df_storm['Longitude'].str.rstrip('.')\n",
    "\n",
    "# Añadir valores anómalos de latitud y longitud a listas\n",
    "anomalous_lat = []\n",
    "anomalous_lon = []\n",
    "\n",
    "# Función para convertir coordenadas y detectar anomalías\n",
    "def convert_coordinates(x, convert_nan=True):\n",
    "    if not x:\n",
    "        return np.nan\n",
    "\n",
    "    # Remover caracteres 'N' y 'E'\n",
    "    x = x.replace(' N', '').replace(' E', '')\n",
    "\n",
    "    # Remover puntos extra en decimales\n",
    "    x = re.sub('^(\\d+\\.\\d{2})\\..*', r'\\1', x)\n",
    "\n",
    "    # Conversión a negativo para S y W\n",
    "    try:\n",
    "        value = float(x)\n",
    "        if x[-1] == 'S' or x[-1] == 'W':\n",
    "            return -value\n",
    "        else:\n",
    "            return value\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# Convertir a float\n",
    "df_storm['Latitude'] = df_storm['Latitude'].apply(convert_coordinates)\n",
    "df_storm['Longitude'] = df_storm['Longitude'].apply(convert_coordinates)\n",
    "\n",
    "# Redondear decimales\n",
    "df_storm['Latitude'] = df_storm['Latitude'].round(2)\n",
    "df_storm['Longitude'] = df_storm['Longitude'].round(2)\n",
    "\n",
    "# Identificar valores anómalos de latitude y longitude\n",
    "for index, row in df_storm.iterrows():\n",
    "    latitude = row['Latitude']\n",
    "    longitude = row['Longitude']\n",
    "\n",
    "    if latitude < -90 or latitude > 90:\n",
    "        anomalous_lat.append(index)\n",
    "\n",
    "    if longitude < -180 or longitude > 180:\n",
    "        anomalous_lon.append(index)\n",
    "\n",
    "# Revisar inconsistencias de cantidad entre anómalos de latitude y longitude\n",
    "if len(anomalous_lat) != len(anomalous_lon):\n",
    "    print(\"Valores inconsistentes de latitud y longitud.\")\n",
    "    # Gestionar la inconsistencia, como remover los valores extras o ajustar las listas\n",
    "    # Por ejemplo, remover los valores extra de latitud:\n",
    "    anomalous_lat = anomalous_lat[:len(anomalous_lon)]\n",
    "    print(\"Longitud de latitud anómala ajustada:\", len(anomalous_lat))\n",
    "\n",
    "# Crear nuevo DataFrame con coordenadas limpias y emparejadas\n",
    "df_eqcleaned = df_storm.copy()\n",
    "\n",
    "# Función para rellenar coordenadas anómalas usando geocoding\n",
    "def fill_anomalous_coordinates(row):\n",
    "    if row.name in anomalous_lat and row.name in anomalous_lon:\n",
    "        try:\n",
    "            location = geolocator.reverse((row['Latitude'], row['Longitude']), timeout=10)\n",
    "            if location and location.latitude is not None and location.longitude is not None:\n",
    "                row['Latitude'] = location.latitude\n",
    "                row['Longitude'] = location.longitude\n",
    "                row['Location'] = location.address\n",
    "                row['Country'] = location.raw['address'].get('country')\n",
    "        except:\n",
    "            pass\n",
    "    return row\n",
    "\n",
    "# Rellenar coordenadas anómalas\n",
    "df_eqcleaned = df_eqcleaned.apply(fill_anomalous_coordinates, axis=1)\n",
    "\n",
    "# Borrar filas con location y country no emparejadas\n",
    "df_eqcleaned = df_eqcleaned[~((df_eqcleaned['Latitude'].isin(anomalous_lat)) & (df_eqcleaned['Longitude'].isin(anomalous_lon)))]\n",
    "\n",
    "# Borrar filas con valores null o nan en columnas de Latitud y Longitud\n",
    "df_eqcleaned = df_eqcleaned.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "# Convertir Latitud y Longitud a float con 2 decimales\n",
    "df_eqcleaned['Latitude'] = df_eqcleaned['Latitude'].astype(float).round(2)\n",
    "df_eqcleaned['Longitude'] = df_eqcleaned['Longitude'].astype(float).round(2)\n",
    "\n",
    "# # Exportar el DataFrame limpio a archivo\n",
    "# df_eqcleaned.to_csv('stormfilteredcleanedgeoloc.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Definimos la función fill_anomalous_latlon que toma una fila como entrada. Si los valores de latitud y longitud de la fila se encuentran en las listas anomalous_lat y anomalous_lon, respectivamente, la función intenta geocodificar la ubicación mediante la columna Location o la columna Country. Si se encuentra una ubicación válida, se actualizan los valores de latitud y longitud de la fila.\n",
    "\n",
    "2. La llamada a la función sleep(1) agrega un retraso de 1 segundo entre las solicitudes de geolocalización para cumplir con la política de uso del servicio de geocodificación.\n",
    "\n",
    "3. Luego creamos un objeto geolocalizador utilizando el geocodificador Nominatim de la biblioteca geopy.\n",
    "\n",
    "4. Finalmente, aplicamos la función fill_anomalous_latlon a cada fila del DataFrame usando el método apply con axis=1, lo que indica que la función debe aplicarse por filas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función con geopy para limpiar coordenadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de verificación de limpieza de coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Efate, Shepherds</td>\n",
       "      <td>Vanuatu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jonesboro (Arkansas)</td>\n",
       "      <td>United States of America (the)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America (the)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Binh Dinh</td>\n",
       "      <td>Viet Nam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America (the)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Czechoslovakia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East Berlin</td>\n",
       "      <td>Germany Dem Rep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany Dem Rep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany Fed Rep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dominica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Latitude  Longitude              Location  \\\n",
       "1959       NaN        NaN      Efate, Shepherds   \n",
       "1962       NaN        NaN  Jonesboro (Arkansas)   \n",
       "1965       NaN        NaN                   NaN   \n",
       "1966       NaN        NaN             Binh Dinh   \n",
       "1968       NaN        NaN                   NaN   \n",
       "...        ...        ...                   ...   \n",
       "2288       NaN        NaN                   NaN   \n",
       "2289       NaN        NaN           East Berlin   \n",
       "2290       NaN        NaN                   NaN   \n",
       "2291       NaN        NaN                   NaN   \n",
       "2292       NaN        NaN                   NaN   \n",
       "\n",
       "                             Country  \n",
       "1959                         Vanuatu  \n",
       "1962  United States of America (the)  \n",
       "1965  United States of America (the)  \n",
       "1966                        Viet Nam  \n",
       "1968  United States of America (the)  \n",
       "...                              ...  \n",
       "2288                  Czechoslovakia  \n",
       "2289                 Germany Dem Rep  \n",
       "2290                 Germany Dem Rep  \n",
       "2291                 Germany Fed Rep  \n",
       "2292                        Dominica  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm[['Latitude', 'Longitude', 'Location', 'Country']][700:800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Filtrar DataFrame para detectar valores anómalos de latitud y longitud\n",
    "df_eqanomalous = df_storm[\n",
    "    df_storm['Latitude'].isin(anomalous_lat) | df_storm['Longitude'].isin(anomalous_lon)\n",
    "]\n",
    "\n",
    "# Crear pivot table para comparar las columnas de latitude, longitude, location, y country\n",
    "df_eqanomalous_pivot = df_eqanomalous.pivot_table(\n",
    "    index=['Location', 'Country'],\n",
    "    values=['Latitude', 'Longitude'],\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "# Mostrar la pivot table\n",
    "print(df_eqanomalous_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7       NaN\n",
      "14      NaN\n",
      "18      NaN\n",
      "19      NaN\n",
      "22      NaN\n",
      "         ..\n",
      "16624   NaN\n",
      "16625   NaN\n",
      "16626   NaN\n",
      "16627   NaN\n",
      "16633   NaN\n",
      "Name: Latitude, Length: 4618, dtype: float64\n",
      "7       NaN\n",
      "14      NaN\n",
      "18      NaN\n",
      "19      NaN\n",
      "22      NaN\n",
      "         ..\n",
      "16624   NaN\n",
      "16625   NaN\n",
      "16626   NaN\n",
      "16627   NaN\n",
      "16633   NaN\n",
      "Name: Longitude, Length: 4618, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_storm['Latitude'])\n",
    "print(df_storm['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(df_storm['Latitude'].dtype)\n",
    "print(df_storm['Longitude'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Examinar filas específicas para verificar si el proceso de limpieza ha manejado los valores anómalos correctamente.\n",
    "# print(df_storm.loc[6000, 'Latitude'])\n",
    "# print(df_storm.loc[6000, 'Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Longitude    4504\n",
       "Latitude     4504\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores nulos de Longitude y Latitude\n",
    "df_storm[['Longitude', 'Latitude']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores Anómalos de Latitud y Longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anomalous_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anomalous_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Índices Anómalos de Latitud y longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índices Anómalos de Latitud: []\n"
     ]
    }
   ],
   "source": [
    "anomalous_lat_idx = []\n",
    "for index, lat in enumerate(anomalous_lat):\n",
    "    if lat < -90 or lat > 90:\n",
    "        anomalous_lat_idx.append(index)\n",
    "\n",
    "print(\"Índices Anómalos de Latitud:\", anomalous_lat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índices Anómalos de Longitud: []\n"
     ]
    }
   ],
   "source": [
    "anomalous_lon_idx = []\n",
    "for index, lon in enumerate(anomalous_lon):\n",
    "    if lat < -90 or lat > 90:\n",
    "        anomalous_lon_idx.append(index)\n",
    "\n",
    "print(\"Índices Anómalos de Longitud:\", anomalous_lon_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers de Latitude y Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(df_storm['Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(df_storm['Longitude'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4618 entries, 7 to 16633\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Dis No             4618 non-null   object \n",
      " 1   Year               4618 non-null   int64  \n",
      " 2   Seq                4618 non-null   int64  \n",
      " 3   Disaster Subgroup  4618 non-null   object \n",
      " 4   Disaster Type      4618 non-null   object \n",
      " 5   Disaster Subtype   3803 non-null   object \n",
      " 6   Country            4618 non-null   object \n",
      " 7   ISO                4618 non-null   object \n",
      " 8   Region             4618 non-null   object \n",
      " 9   Continent          4618 non-null   object \n",
      " 10  Location           3882 non-null   object \n",
      " 11  Origin             48 non-null     object \n",
      " 12  Associated Dis     1345 non-null   object \n",
      " 13  Dis Mag Value      4618 non-null   int64  \n",
      " 14  Dis Mag Scale      4618 non-null   object \n",
      " 15  Latitude           114 non-null    float64\n",
      " 16  Longitude          114 non-null    float64\n",
      " 17  Start Year         4618 non-null   int64  \n",
      " 18  Start Month        4618 non-null   int64  \n",
      " 19  Start Day          4618 non-null   int64  \n",
      " 20  End Year           4618 non-null   int64  \n",
      " 21  End Month          4618 non-null   int64  \n",
      " 22  End Day            4618 non-null   int64  \n",
      " 23  Total Deaths       4618 non-null   int64  \n",
      " 24  Total Affected     4618 non-null   int64  \n",
      " 25  Total Damages Adj  4618 non-null   int64  \n",
      "dtypes: float64(2), int64(12), object(12)\n",
      "memory usage: 974.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_storm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dis No                  0\n",
       "Year                    0\n",
       "Seq                     0\n",
       "Disaster Subgroup       0\n",
       "Disaster Type           0\n",
       "Disaster Subtype      815\n",
       "Country                 0\n",
       "ISO                     0\n",
       "Region                  0\n",
       "Continent               0\n",
       "Location              736\n",
       "Origin               4570\n",
       "Associated Dis       3273\n",
       "Dis Mag Value           0\n",
       "Dis Mag Scale           0\n",
       "Latitude             4504\n",
       "Longitude            4504\n",
       "Start Year              0\n",
       "Start Month             0\n",
       "Start Day               0\n",
       "End Year                0\n",
       "End Month               0\n",
       "End Day                 0\n",
       "Total Deaths            0\n",
       "Total Affected          0\n",
       "Total Damages Adj       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputar valores anómalos con SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4504"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Seleccionar filas donde 'Longitude' está (isin) la lista de anomalous_lon\n",
    "anomalous_lat_to_impute = df_storm['Latitude'].isin(anomalous_lat)\n",
    "\n",
    "# Imputar los valores con la media a anomalous_lon en 'Longitude'\n",
    "df_storm.loc[anomalous_lat_to_impute, 'Latitude'] = imputer.fit_transform(df_storm[['Latitude']])[anomalous_lat_to_impute]\n",
    "df_storm['Latitude'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7        True\n",
       "14       True\n",
       "18       True\n",
       "19       True\n",
       "22       True\n",
       "         ... \n",
       "16624    True\n",
       "16625    True\n",
       "16626    True\n",
       "16627    True\n",
       "16633    True\n",
       "Name: Longitude, Length: 4618, dtype: bool"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Seleccionar filas donde 'Longitude' está (isin) la lista de anomalous_lon\n",
    "anomalous_lon_to_impute = df_storm['Longitude'].isin(anomalous_lon)\n",
    "\n",
    "# Imputar los valores anómalos con la media a anomalous_lon en 'Longitude'\n",
    "df_storm.loc[anomalous_lon_to_impute, 'Longitude'] = imputer.fit_transform(df_storm[['Longitude']])[anomalous_lon_to_impute]\n",
    "df_storm['Longitude'].isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputar mediana a nulos con SimpleImputer a Longitude y Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "# Seleccionar filas donde 'Longitude' sea null (NaN)\n",
    "null_lon_rows = df_storm['Latitude'].isnull()\n",
    "# Imputar los nulls en 'Longitude' estrategia mean\n",
    "df_storm.loc[null_lon_rows, 'Latitude'] = imputer.fit_transform(df_storm[['Latitude']])[null_lon_rows]\n",
    "df_storm['Latitude'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "# Seleccionar filas donde 'Longitude' sea null (NaN)\n",
    "null_lon_rows = df_storm['Longitude'].isnull()\n",
    "# Imputar los nulls en 'Longitude' estrategia mean\n",
    "df_storm.loc[null_lon_rows, 'Longitude'] = imputer.fit_transform(df_storm[['Longitude']])[null_lon_rows]\n",
    "df_storm['Longitude'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Region</th>\n",
       "      <th>Continent</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Total Damages Adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904-0003-BGD</td>\n",
       "      <td>1904</td>\n",
       "      <td>3</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BGD</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>104.125</td>\n",
       "      <td>1904</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1904</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1906-0015-HKG</td>\n",
       "      <td>1906</td>\n",
       "      <td>15</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>HKG</td>\n",
       "      <td>Eastern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>104.125</td>\n",
       "      <td>1906</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1906</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>649981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1909-0010-BGD</td>\n",
       "      <td>1909</td>\n",
       "      <td>10</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BGD</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>104.125</td>\n",
       "      <td>1909</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1909</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1909-0013-BGD</td>\n",
       "      <td>1909</td>\n",
       "      <td>13</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BGD</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>...</td>\n",
       "      <td>104.125</td>\n",
       "      <td>1909</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1909</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1909-0012-HTI</td>\n",
       "      <td>1909</td>\n",
       "      <td>12</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>HTI</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>Americas</td>\n",
       "      <td>...</td>\n",
       "      <td>104.125</td>\n",
       "      <td>1909</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1909</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dis No  Year  Seq Disaster Subgroup Disaster Type  \\\n",
       "7   1904-0003-BGD  1904    3    Meteorological         Storm   \n",
       "14  1906-0015-HKG  1906   15    Meteorological         Storm   \n",
       "18  1909-0010-BGD  1909   10    Meteorological         Storm   \n",
       "19  1909-0013-BGD  1909   13    Meteorological         Storm   \n",
       "22  1909-0012-HTI  1909   12    Meteorological         Storm   \n",
       "\n",
       "    Disaster Subtype     Country  ISO         Region Continent  ... Longitude  \\\n",
       "7   Tropical cyclone  Bangladesh  BGD  Southern Asia      Asia  ...   104.125   \n",
       "14  Tropical cyclone   Hong Kong  HKG   Eastern Asia      Asia  ...   104.125   \n",
       "18  Tropical cyclone  Bangladesh  BGD  Southern Asia      Asia  ...   104.125   \n",
       "19  Tropical cyclone  Bangladesh  BGD  Southern Asia      Asia  ...   104.125   \n",
       "22  Tropical cyclone       Haiti  HTI      Caribbean  Americas  ...   104.125   \n",
       "\n",
       "   Start Year Start Month  Start Day End Year  End Month  End Day  \\\n",
       "7        1904          11          0     1904         11        0   \n",
       "14       1906           9          8     1906          9        8   \n",
       "18       1909          10         15     1909         10       15   \n",
       "19       1909          12          0     1909         12        0   \n",
       "22       1909          11         12     1909         11       12   \n",
       "\n",
       "    Total Deaths  Total Affected  Total Damages Adj  \n",
       "7              0               0                  0  \n",
       "14         10000               0             649981  \n",
       "18           172               0                  0  \n",
       "19             0               0                  0  \n",
       "22           150               0                  0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\581366220.py:1: FutureWarning: pivot_table dropped a column because it failed to aggregate. This behavior is deprecated and will raise in a future version of pandas. Select only the columns that can be aggregated.\n",
      "  df_storm_origin_geolocation_pivot = df_storm.pivot_table(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Latitude</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Convective storm</th>\n",
       "      <th>Tropical cyclone</th>\n",
       "      <th>Convective storm</th>\n",
       "      <th>Tropical cyclone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arctic blast associated with the Polar Vortex</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brief torrential rains</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cold front meeting warm, moist air</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Days of rains and hails</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>El Nino phenomenom</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Formed by the remnants of tropical cyclone GULAB</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heavy monsoonal rain</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heavy rain</th>\n",
       "      <td>19.73</td>\n",
       "      <td>54.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>239.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heavy rains</th>\n",
       "      <td>114.99</td>\n",
       "      <td>19.73</td>\n",
       "      <td>329.220</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heavy rains and strong winds</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heavy rains, remnants of tropical storm Fred</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heavy snowfall and very low temperatures</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low pressure 'Kolle'</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mei-Yu</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monsoon</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monsoonal rain</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.000</td>\n",
       "      <td>83.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pacific storm systems fueled by El Nino</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polar Vortex</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precursor of Damrey</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Remnant low pressure system of cyclone Hudhud</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snowstorm</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stro,gs wnds and heav rains</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strong winds</th>\n",
       "      <td>59.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>312.375</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail-end of a frontal system</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thunderstorm</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Torrential rain</th>\n",
       "      <td>38.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-80.560</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Torrential rains</th>\n",
       "      <td>39.46</td>\n",
       "      <td>19.73</td>\n",
       "      <td>208.250</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tropical cyclone Cuba</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>149.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tropical storm Peipah</th>\n",
       "      <td>0.00</td>\n",
       "      <td>17.57</td>\n",
       "      <td>0.000</td>\n",
       "      <td>121.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violents orages et impressionnantes crues d'oueds</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Latitude  \\\n",
       "Disaster Subtype                                  Convective storm   \n",
       "Origin                                                               \n",
       "Arctic blast associated with the Polar Vortex                19.73   \n",
       "Brief torrential rains                                       19.73   \n",
       "Cold front meeting warm, moist air                           19.73   \n",
       "Days of rains and hails                                      19.73   \n",
       "El Nino phenomenom                                            0.00   \n",
       "Formed by the remnants of tropical cyclone GULAB              0.00   \n",
       "Heavy monsoonal rain                                         19.73   \n",
       "Heavy rain                                                   19.73   \n",
       "Heavy rains                                                 114.99   \n",
       "Heavy rains and strong winds                                 19.73   \n",
       "Heavy rains, remnants of tropical storm Fred                  0.00   \n",
       "Heavy snowfall and very low temperatures                     19.73   \n",
       "Low pressure 'Kolle'                                         19.73   \n",
       "Mei-Yu                                                       19.73   \n",
       "Monsoon                                                      19.73   \n",
       "Monsoonal rain                                                0.00   \n",
       "Pacific storm systems fueled by El Nino                      19.73   \n",
       "Polar Vortex                                                 19.73   \n",
       "Precursor of Damrey                                           0.00   \n",
       "Remnant low pressure system of cyclone Hudhud                19.73   \n",
       "Snowstorm                                                    19.73   \n",
       "Stro,gs wnds and heav rains                                  19.73   \n",
       "Strong winds                                                 59.19   \n",
       "Tail-end of a frontal system                                 19.73   \n",
       "Thunderstorm                                                 19.73   \n",
       "Torrential rain                                              38.94   \n",
       "Torrential rains                                             39.46   \n",
       "Tropical cyclone Cuba                                         0.00   \n",
       "Tropical storm Peipah                                         0.00   \n",
       "Violents orages et impressionnantes crues d'oueds            19.73   \n",
       "\n",
       "                                                                    \\\n",
       "Disaster Subtype                                  Tropical cyclone   \n",
       "Origin                                                               \n",
       "Arctic blast associated with the Polar Vortex                 0.00   \n",
       "Brief torrential rains                                        0.00   \n",
       "Cold front meeting warm, moist air                            0.00   \n",
       "Days of rains and hails                                       0.00   \n",
       "El Nino phenomenom                                           19.73   \n",
       "Formed by the remnants of tropical cyclone GULAB             19.73   \n",
       "Heavy monsoonal rain                                          0.00   \n",
       "Heavy rain                                                   54.00   \n",
       "Heavy rains                                                  19.73   \n",
       "Heavy rains and strong winds                                  0.00   \n",
       "Heavy rains, remnants of tropical storm Fred                 19.73   \n",
       "Heavy snowfall and very low temperatures                      0.00   \n",
       "Low pressure 'Kolle'                                          0.00   \n",
       "Mei-Yu                                                        0.00   \n",
       "Monsoon                                                       0.00   \n",
       "Monsoonal rain                                               19.73   \n",
       "Pacific storm systems fueled by El Nino                       0.00   \n",
       "Polar Vortex                                                  0.00   \n",
       "Precursor of Damrey                                          19.73   \n",
       "Remnant low pressure system of cyclone Hudhud                 0.00   \n",
       "Snowstorm                                                     0.00   \n",
       "Stro,gs wnds and heav rains                                   0.00   \n",
       "Strong winds                                                  0.00   \n",
       "Tail-end of a frontal system                                  0.00   \n",
       "Thunderstorm                                                  0.00   \n",
       "Torrential rain                                               0.00   \n",
       "Torrential rains                                             19.73   \n",
       "Tropical cyclone Cuba                                        -9.03   \n",
       "Tropical storm Peipah                                        17.57   \n",
       "Violents orages et impressionnantes crues d'oueds             0.00   \n",
       "\n",
       "                                                         Longitude  \\\n",
       "Disaster Subtype                                  Convective storm   \n",
       "Origin                                                               \n",
       "Arctic blast associated with the Polar Vortex              104.125   \n",
       "Brief torrential rains                                     104.125   \n",
       "Cold front meeting warm, moist air                         104.125   \n",
       "Days of rains and hails                                    104.125   \n",
       "El Nino phenomenom                                           0.000   \n",
       "Formed by the remnants of tropical cyclone GULAB             0.000   \n",
       "Heavy monsoonal rain                                       104.125   \n",
       "Heavy rain                                                 104.125   \n",
       "Heavy rains                                                329.220   \n",
       "Heavy rains and strong winds                               104.125   \n",
       "Heavy rains, remnants of tropical storm Fred                 0.000   \n",
       "Heavy snowfall and very low temperatures                   104.125   \n",
       "Low pressure 'Kolle'                                       104.125   \n",
       "Mei-Yu                                                     104.125   \n",
       "Monsoon                                                    104.125   \n",
       "Monsoonal rain                                               0.000   \n",
       "Pacific storm systems fueled by El Nino                    104.125   \n",
       "Polar Vortex                                               104.125   \n",
       "Precursor of Damrey                                          0.000   \n",
       "Remnant low pressure system of cyclone Hudhud              104.125   \n",
       "Snowstorm                                                  104.125   \n",
       "Stro,gs wnds and heav rains                                104.125   \n",
       "Strong winds                                               312.375   \n",
       "Tail-end of a frontal system                               104.125   \n",
       "Thunderstorm                                               104.125   \n",
       "Torrential rain                                            -80.560   \n",
       "Torrential rains                                           208.250   \n",
       "Tropical cyclone Cuba                                        0.000   \n",
       "Tropical storm Peipah                                        0.000   \n",
       "Violents orages et impressionnantes crues d'oueds          104.125   \n",
       "\n",
       "                                                                    \n",
       "Disaster Subtype                                  Tropical cyclone  \n",
       "Origin                                                              \n",
       "Arctic blast associated with the Polar Vortex                0.000  \n",
       "Brief torrential rains                                       0.000  \n",
       "Cold front meeting warm, moist air                           0.000  \n",
       "Days of rains and hails                                      0.000  \n",
       "El Nino phenomenom                                         104.125  \n",
       "Formed by the remnants of tropical cyclone GULAB           104.125  \n",
       "Heavy monsoonal rain                                         0.000  \n",
       "Heavy rain                                                 239.820  \n",
       "Heavy rains                                                104.125  \n",
       "Heavy rains and strong winds                                 0.000  \n",
       "Heavy rains, remnants of tropical storm Fred               104.125  \n",
       "Heavy snowfall and very low temperatures                     0.000  \n",
       "Low pressure 'Kolle'                                         0.000  \n",
       "Mei-Yu                                                       0.000  \n",
       "Monsoon                                                      0.000  \n",
       "Monsoonal rain                                              83.750  \n",
       "Pacific storm systems fueled by El Nino                      0.000  \n",
       "Polar Vortex                                                 0.000  \n",
       "Precursor of Damrey                                        104.125  \n",
       "Remnant low pressure system of cyclone Hudhud                0.000  \n",
       "Snowstorm                                                    0.000  \n",
       "Stro,gs wnds and heav rains                                  0.000  \n",
       "Strong winds                                                 0.000  \n",
       "Tail-end of a frontal system                                 0.000  \n",
       "Thunderstorm                                                 0.000  \n",
       "Torrential rain                                              0.000  \n",
       "Torrential rains                                           104.125  \n",
       "Tropical cyclone Cuba                                      149.220  \n",
       "Tropical storm Peipah                                      121.760  \n",
       "Violents orages et impressionnantes crues d'oueds            0.000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm_origin_geolocation_pivot = df_storm.pivot_table(\n",
    "    index='Origin',\n",
    "    columns='Disaster Subtype',\n",
    "    values=['Latitude', 'Longitude', 'Location'],\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "df_storm_origin_geolocation_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AleEng\\AppData\\Local\\Temp\\ipykernel_17332\\274561833.py:1: FutureWarning: pivot_table dropped a column because it failed to aggregate. This behavior is deprecated and will raise in a future version of pandas. Select only the columns that can be aggregated.\n",
      "  df_storm_year_geolocation_pivot = df_storm.pivot_table(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Latitude</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Convective storm</th>\n",
       "      <th>Extra-tropical storm</th>\n",
       "      <th>Tropical cyclone</th>\n",
       "      <th>Convective storm</th>\n",
       "      <th>Extra-tropical storm</th>\n",
       "      <th>Tropical cyclone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>19.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>104.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.73</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>789.20</td>\n",
       "      <td>118.38</td>\n",
       "      <td>868.12</td>\n",
       "      <td>4165.000</td>\n",
       "      <td>624.750</td>\n",
       "      <td>4581.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>690.55</td>\n",
       "      <td>277.18</td>\n",
       "      <td>1524.45</td>\n",
       "      <td>3644.375</td>\n",
       "      <td>1458.805</td>\n",
       "      <td>8170.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>1144.34</td>\n",
       "      <td>19.73</td>\n",
       "      <td>1144.34</td>\n",
       "      <td>6039.250</td>\n",
       "      <td>104.125</td>\n",
       "      <td>6039.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>808.93</td>\n",
       "      <td>335.41</td>\n",
       "      <td>986.50</td>\n",
       "      <td>4269.125</td>\n",
       "      <td>1770.125</td>\n",
       "      <td>5206.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>315.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>197.30</td>\n",
       "      <td>1666.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1041.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Latitude                                        \\\n",
       "Disaster Subtype Convective storm Extra-tropical storm Tropical cyclone   \n",
       "Year                                                                      \n",
       "1900                         0.00                 0.00            19.73   \n",
       "1902                         0.00                 0.00            19.73   \n",
       "1903                        19.73                 0.00            19.73   \n",
       "1904                         0.00                 0.00            19.73   \n",
       "1905                         0.00                 0.00            19.73   \n",
       "...                           ...                  ...              ...   \n",
       "2019                       789.20               118.38           868.12   \n",
       "2020                       690.55               277.18          1524.45   \n",
       "2021                      1144.34                19.73          1144.34   \n",
       "2022                       808.93               335.41           986.50   \n",
       "2023                       315.68                 0.00           197.30   \n",
       "\n",
       "                        Longitude                                        \n",
       "Disaster Subtype Convective storm Extra-tropical storm Tropical cyclone  \n",
       "Year                                                                     \n",
       "1900                        0.000                0.000          104.125  \n",
       "1902                        0.000                0.000          104.125  \n",
       "1903                      104.125                0.000          104.125  \n",
       "1904                        0.000                0.000          104.125  \n",
       "1905                        0.000                0.000          104.125  \n",
       "...                           ...                  ...              ...  \n",
       "2019                     4165.000              624.750         4581.500  \n",
       "2020                     3644.375             1458.805         8170.520  \n",
       "2021                     6039.250              104.125         6039.250  \n",
       "2022                     4269.125             1770.125         5206.250  \n",
       "2023                     1666.000                0.000         1041.250  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm_year_geolocation_pivot = df_storm.pivot_table(\n",
    "    index='Year',\n",
    "    columns='Disaster Subtype',\n",
    "    values=['Latitude', 'Longitude', 'Location'],\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "df_storm_year_geolocation_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar dataset Storm limpio en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\..\\Data\\03Limpio\\StormLimpioCSV'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39m../../Data/03Limpio/StormLimpioCSV/03desastres_3stormcoordlimpias.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 734\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    737\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AleEng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    595\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '..\\..\\Data\\03Limpio\\StormLimpioCSV'"
     ]
    }
   ],
   "source": [
    "df.to_csv('../../Data/03Limpio/StormLimpioCSV/03desastres_3stormcoordlimpias.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
